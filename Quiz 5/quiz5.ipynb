{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca5d3a95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by getOrCreate at /var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/4020386847.py:6 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split, col, udf\n\u001b[1;32m     10\u001b[0m conf \u001b[38;5;241m=\u001b[39m SparkConf()\u001b[38;5;241m.\u001b[39msetMaster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myarn-client\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext(conf \u001b[38;5;241m=\u001b[39m conf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    204\u001b[0m         master,\n\u001b[1;32m    205\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/context.py:449\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    446\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    454\u001b[0m             currentAppName,\n\u001b[1;32m    455\u001b[0m             currentMaster,\n\u001b[1;32m    456\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    457\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    458\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by getOrCreate at /var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/4020386847.py:6 "
     ]
    }
   ],
   "source": [
    "import pyspark as spark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import split, col, udf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba571006",
   "metadata": {},
   "source": [
    "## Part 1 Accumulators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208c35a",
   "metadata": {},
   "source": [
    "### Corrected Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd728f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/21 11:53:18 ERROR Executor: Exception in task 1.0 in stage 54.0 (TID 178)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n",
      "    f(x)\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/10/21 11:53:18 ERROR Executor: Exception in task 4.0 in stage 54.0 (TID 181)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n",
      "    f(x)\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/10/21 11:53:18 ERROR Executor: Exception in task 6.0 in stage 54.0 (TID 183)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n",
      "    f(x)\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/10/21 11:53:18 ERROR Executor: Exception in task 7.0 in stage 54.0 (TID 184)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n",
      "    f(x)\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/10/21 11:53:18 WARN TaskSetManager: Lost task 6.0 in stage 54.0 (TID 183) (macbook executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n",
      "    f(x)\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "24/10/21 11:53:18 ERROR Executor: Exception in task 3.0 in stage 54.0 (TID 180)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n",
      "    process()\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n",
      "    return f(iterator)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n",
      "    f(x)\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n",
      "  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "24/10/21 11:53:18 ERROR TaskSetManager: Task 6 in stage 54.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 54.0 failed 1 times, most recent failure: Lost task 6.0 in stage 54.0 (TID 183) (macbook executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n    out_iter = func(split_index, iterator)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n    f(x)\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n    raise PySparkRuntimeError(\npyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n    out_iter = func(split_index, iterator)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n    f(x)\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n    raise PySparkRuntimeError(\npyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 27\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melement\u001b[39m\u001b[38;5;124m'\u001b[39m,x,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccumulated counter\u001b[39m\u001b[38;5;124m'\u001b[39m,counter\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     global_counter = global_counter + x\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     counter = global_counter\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     print(counter)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#     return result\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m rdd\u001b[38;5;241m.\u001b[39mforeach(accum)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py:1766\u001b[0m, in \u001b[0;36mRDD.foreach\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         f(x)\n\u001b[1;32m   1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m([])\n\u001b[0;32m-> 1766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapPartitions(processPartition)\u001b[38;5;241m.\u001b[39mcount()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py:2316\u001b[0m, in \u001b[0;36mRDD.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapPartitions(\u001b[38;5;28;01mlambda\u001b[39;00m i: [\u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m i)])\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py:2291\u001b[0m, in \u001b[0;36mRDD.sum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2289\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[1;32m   2290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapPartitions(\u001b[38;5;28;01mlambda\u001b[39;00m x: [\u001b[38;5;28msum\u001b[39m(x)])\u001b[38;5;241m.\u001b[39mfold(  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m   2292\u001b[0m         \u001b[38;5;241m0\u001b[39m, operator\u001b[38;5;241m.\u001b[39madd\n\u001b[1;32m   2293\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py:2044\u001b[0m, in \u001b[0;36mRDD.fold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[0;32m-> 2044\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapPartitions(func)\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py:1833\u001b[0m, in \u001b[0;36mRDD.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1833\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonRDD\u001b[38;5;241m.\u001b[39mcollectAndServe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd\u001b[38;5;241m.\u001b[39mrdd())\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 54.0 failed 1 times, most recent failure: Lost task 6.0 in stage 54.0 (TID 183) (macbook executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n    out_iter = func(split_index, iterator)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n    f(x)\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n    raise PySparkRuntimeError(\npyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2393)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2414)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2433)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2458)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1049)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:410)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1048)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:195)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1247, in main\n    process()\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1237, in process\n    out_iter = func(split_index, iterator)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 5434, in pipeline_func\n    return func(split, prev_func(split, iterator))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 840, in func\n    return f(iterator)\n           ^^^^^^^^^^^\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/rdd.py\", line 1763, in processPartition\n    f(x)\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/util.py\", line 83, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/ck/1xc3_hrd4556zhtcl0bbnq9r0000gn/T/ipykernel_1099/1493937427.py\", line 21, in accum\n  File \"/Users/nanxiliu/anaconda3/lib/python3.11/site-packages/pyspark/python/lib/pyspark.zip/pyspark/accumulators.py\", line 147, in value\n    raise PySparkRuntimeError(\npyspark.errors.exceptions.base.PySparkRuntimeError: [VALUE_NOT_ACCESSIBLE] Value `Accumulator.value` cannot be accessed inside tasks.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:784)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:766)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1049)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2433)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "data = [1,2,3,4,5]\n",
    "counter = sc.accumulator(0)\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "def print_ (x):\n",
    "  print (x)\n",
    "  return x\n",
    "# \n",
    "# rdd.foreach(print_)\n",
    "# 4\n",
    "# 5\n",
    "# 3\n",
    "# 2\n",
    "# 1\n",
    "\n",
    "def accum(x):\n",
    "    global counter\n",
    "    counter += x\n",
    "    \n",
    "    print('element',x,'accumulated counter',counter.value)\n",
    "#     global_counter = global_counter + x\n",
    "#     counter = global_counter\n",
    "#     print(counter)\n",
    "#     return result\n",
    "\n",
    "rdd.foreach(accum)\n",
    "# rdd.foreach(print_)\n",
    "# Error messages ensue\n",
    "# 24/10/18 12:47:09 ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 28)\n",
    "# org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
    "#  File \"/usr/sup/Python-3.9.2/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
    "#    process()\n",
    "#  File \"/usr/sup/Python-3.9.2/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4910374",
   "metadata": {},
   "source": [
    "## Part 2 Airlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6091b07",
   "metadata": {},
   "source": [
    "### Reading files as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04e14d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+---+--------+---+---+---+----+---+---+----+---+---+---+---+---+---+---+----+----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+---+\n",
      "|  A|   B|  C|  D|       E|  F|  G|  H|   I|  J|  K|   L|  M|  N|  O|  P|  Q|  R|  S|   T|   U|     V|  W|  X|  Y|  Z| AA| AB|_33|_34|_35|_36|_37|_38|_39|_40|_41|_42|_43|_44|_45|_46|_47|_48|_49|_50|_51|_52|_53|_54|_55|_56|_57|_58|_59|_60|_61|_62|_63|_64|_65|_66|_67|_68|_69|   _70|_71|\n",
      "+---+----+---+---+--------+---+---+---+----+---+---+----+---+---+---+---+---+---+---+----+----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+---+\n",
      "| DL|4800|CHS|JFK|20240607|  5|700|700| 650|900|900| 841|  0|  0|120|111|-10|-19| -9| 705| 830|N272PQ| 15| 11| 85|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240608|  6|700|700| 654|900|900| 849|  0|  0|120|115| -6|-11| -5| 708| 841|N302PQ| 14|  8| 93|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240609|  7|700|700| 656|900|900| 848|  0|  0|120|112| -4|-12| -8| 710| 840|N676CA| 14|  8| 90|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240610|  1|700|700|1043|900|900|1220|  0|  0|120| 97|223|200|-23|1056|1214|N301PQ| 13|  6| 78|   |  4|  0|  0|  0|196|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240611|  2|700|700| 657|900|900| 847|  0|  0|120|110| -3|-13|-10| 715| 840|N335PQ| 18|  7| 85|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240612|  3|700|700| 658|900|900| 842|  0|  0|120|104| -2|-18|-16| 713| 836|N932XJ| 15|  6| 83|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240613|  4|700|700|1817|900|900|2106|  0|  0|120|169|677|726| 49|1917|2045|N691CA| 60| 21| 88|   |677|  0| 49|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240614|  5|700|700| 659|900|900| 848|  0|  0|120|109| -1|-12|-11| 711| 840|N186PQ| 12|  8| 89|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240615|  6|700|700| 659|900|900| 852|  0|  0|120|113| -1| -8| -7| 714| 841|N604LR| 15| 11| 87|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240616|  7|700|700| 658|900|900| 844|  0|  0|120|106| -2|-16|-14| 707| 837|N316PQ|  9|  7| 90|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240617|  1|700|700| 659|900|900| 848|  0|  0|120|109| -1|-12|-11| 714| 842|N279PQ| 15|  6| 88|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240618|  2|700|700| 706|900|900| 902|  0|  0|120|116|  6|  2| -4| 719| 853|N294PQ| 13|  9| 94|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240619|  3|700|700| 652|900|900| 855|  0|  0|120|123| -8| -5|  3| 710| 844|N296PQ| 18| 11| 94|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240620|  4|700|700| 659|900|900| 858|  0|  0|120|119| -1| -2| -1| 716| 851|N601LR| 17|  7| 95|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240621|  5|700|700| 721|900|900| 911|  0|  0|120|110| 21| 11|-10| 732| 905|N606LR| 11|  6| 93|   |  0|  0|  0|  0|  0|655|  3|  3|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240622|  6|700|700| 700|900|900| 858|  0|  0|120|118|  0| -2| -2| 713| 852|N297PQ| 13|  6| 99|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240623|  7|700|700| 654|900|900| 845|  0|  0|120|111| -6|-15| -9| 709| 837|N306PQ| 15|  8| 88|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240624|  1|700|700| 726|900|900| 919|  0|  0|120|113| 26| 19| -7| 743| 908|N136EV| 17| 11| 85|   | 19|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240625|  2|700|700| 652|900|900| 900|  0|  0|120|128| -8|  0|  8| 718| 853|N186PQ| 26|  7| 95|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "| DL|4800|CHS|JFK|20240626|  3|700|700| 650|900|900| 837|  0|  0|120|107|-10|-23|-13| 705| 830|N921XJ| 15|  7| 85|   |  0|  0|  0|  0|  0|  0|  0|  0|  0|   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |   |  0|  0|  0|  0|   |FORM-1|  N|\n",
      "+---+----+---+---+--------+---+---+---+----+---+---+----+---+---+---+---+---+---+---+----+----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "june = spark.read.text(\"airline/ontime.td.202406.asc\")\n",
    "july = spark.read.text(\"ontime.td.202407.asc\")\n",
    "\n",
    "df_june_split = june.select(split(june.value,\"\\\\|\")).rdd.flatMap(\n",
    "              lambda x: x).toDF(schema=['A','B','C_','D_','E_','F_','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','AA','AB'])\n",
    "\n",
    "df_july_split = june.select(split(june.value,\"\\\\|\")).rdd.flatMap(\n",
    "              lambda x: x).toDF(schema=['A','B','C_','D_','E_','F_','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','AA','AB'])\n",
    "total = df_june_split.union(df_july_split)\n",
    "total = total.drop('C_','D_','E_','F_')\n",
    "total.show()\n",
    "\n",
    "\n",
    "# convert strings to int for certain columns\n",
    "\n",
    "\n",
    "total = total.withColumn(\"Q\", total[\"Q\"].cast(IntegerType()))\n",
    "total = total.withColumn(\"R\", total[\"R\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3707110",
   "metadata": {},
   "source": [
    "## Refences for airline and airport acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe4a6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_codes = {\n",
    "    \"ATL\": \"Hartsfield Jackson Atlanta\",\n",
    "    \"BWI\": \"Baltimore/Wash. Int'l Thurgood Marshall\",\n",
    "    \"BOS\": \"Logan International Boston\",\n",
    "    \"CLT\": \"Douglas Charlotte\",\n",
    "    \"MDW\": \"Midway Chicago\",\n",
    "    \"ORD\": \"O'Hare Chicago\",\n",
    "    \"CVG\": \"Greater Cincinnati\",\n",
    "    \"DFW\": \"Dallas-Fort Worth International\",\n",
    "    \"DEN\": \"International Denver\",\n",
    "    \"DTW\": \"Metro Wayne County Detroit\",\n",
    "    \"FLL\": \"Fort Lauderdale Hollywood International\",\n",
    "    \"IAH\": \"George Bush International Houston\",\n",
    "    \"LAS\": \"McCarran International Las Vegas\",\n",
    "    \"LAX\": \"Los Angeles International\",\n",
    "    \"MIA\": \"Miami International\",\n",
    "    \"MSP\": \"Minneapolis-St. Paul International\",\n",
    "    \"EWR\": \"Liberty International Newark\",\n",
    "    \"JFK\": \"JFK International New York\",\n",
    "    \"LGA\": \"LaGuardia New York\",\n",
    "    \"MCO\": \"International Oakland\",\n",
    "    \"OAK\": \"International Orlando\",\n",
    "    \"PHL\": \"International Philadelphia\",\n",
    "    \"PHX\": \"Sky Harbor International Phoenix\",\n",
    "    \"PDX\": \"International Portland\",\n",
    "    \"SLC\": \"International Salt Lake City\",\n",
    "    \"STL\": \"Lambert International St. Louis\",\n",
    "    \"SAN\": \"Intl. Lindbergh Field San Diego\",\n",
    "    \"SFO\": \"International San Francisco\",\n",
    "    \"SEA\": \"International Seattle-Tacoma\",\n",
    "    \"TPA\": \"International Tampa\",\n",
    "    \"DCA\": \"Reagan National Washington\",\n",
    "    \"IAD\": \"Dulles International Washington\",\n",
    "}\n",
    "airline_acronyms = {\n",
    "    \"FL\": \"AirTran\",\n",
    "    \"AS\": \"Alaska\",\n",
    "    \"HP\": \"America West\",\n",
    "    \"AA\": \"American\",\n",
    "    \"MQ\": \"American Eagle\",\n",
    "    \"AS\": \"Atlantic Southeast\",\n",
    "    \"OH\": \"Comair\",\n",
    "    \"CO\": \"Continental\",\n",
    "    \"DL\": \"Delta\",\n",
    "    \"XE\": \"ExpressJet Airlines d/b/a Continental Express\",\n",
    "    \"F9\": \"Frontier\",\n",
    "    \"B6\": \"JetBlue\",\n",
    "    \"YV\": \"Mesa Airlines\",\n",
    "    \"NW\": \"Northwest\",\n",
    "    \"9E\": \"Pinnacle Airlines d/b/a Northwest Airlink\",\n",
    "    \"OO\": \"SkyWest\",\n",
    "    \"WN\": \"Southwest\",\n",
    "    \"UA\": \"United\",\n",
    "    \"US\": \"US Airways\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66917c8",
   "metadata": {},
   "source": [
    "### q2: Which US Airline Has the Least Delays? Report by full names, (e.g., Delta Airlines, not DL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af84a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 131:>                (0 + 2) / 2][Stage 133:>                (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+----------------+------------+\n",
      "|arrival_delays|                 A|departure_delays|total_delays|\n",
      "+--------------+------------------+----------------+------------+\n",
      "|         67141|          American|           66375|      133516|\n",
      "|         56465|         Southwest|           70752|      127217|\n",
      "|         46971|             Delta|           46966|       93937|\n",
      "|         41765|            United|           41237|       83002|\n",
      "|         16429|Atlantic Southeast|           14350|       30779|\n",
      "|          9431|                NK|           10520|       19951|\n",
      "|          9411|          Frontier|            8945|       18356|\n",
      "|          7931|           JetBlue|            8523|       16454|\n",
      "|          4998|                G4|            4845|        9843|\n",
      "|          2898|                HA|            2691|        5589|\n",
      "+--------------+------------------+----------------+------------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_least_delay(df):\n",
    "    '''Q: departure delay. R: arrival delay. A: airline'''\n",
    "#   result = df.groupBy(\"A\").agg(F.count(F.when(col(\"T\") > 0) | F.when(col('S') > 0), col('A')).alias(\"delays\"))\n",
    "    arrival = df.groupBy(\"A\").agg(F.count(F.when(col(\"R\") > 0, col('A'))).alias(\"arrival_delays\"))\n",
    "    departure = df.groupBy(\"A\").agg(F.count(F.when(col(\"Q\") > 0, col('A'))).alias(\"departure_delays\"))\n",
    "    result = arrival.join(departure, arrival.A == departure.A, \"inner\").drop(arrival.A)\n",
    "    function = udf(lambda col1, col2 : col1+col2, IntegerType())\n",
    "    result = result.withColumn('total_delays',function(col('arrival_delays'),col('departure_delays')))\n",
    "    df_replaced = result.na.replace(airline_acronyms, subset=[\"A\"])\n",
    "    return df_replaced.orderBy(\"total_delays\", ascending=False)\n",
    "\n",
    "  # result.show()\n",
    "\n",
    "# print(get_least_delay(total))\n",
    "# print(total.S)\n",
    "print(get_least_delay(total).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe88ff",
   "metadata": {},
   "source": [
    "### q3: What Departure Time of Day Is Best to Avoid Flight Delays, segmented into 5 time blocks [night (10 pm - 6 am), morning (6 am to 10 am), mid-day (10 am to 2 pm), afternoon (2 pm - 6 pm), evening (6 pm - 10 pm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "22e349e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|departure_window|departure_delays|\n",
      "+----------------+----------------+\n",
      "|       afternoon|           76852|\n",
      "|         evening|           74375|\n",
      "|          midday|           61871|\n",
      "|         morning|           44592|\n",
      "|           night|           17514|\n",
      "+----------------+----------------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# step 0: make sure dataframe contains the correct types for scheduled departure\n",
    "total = total.withColumn(\"G\", total[\"G\"].cast(IntegerType()))\n",
    "# total = total.withColumn(\"R\", total[\"R\"].cast(IntegerType()))\n",
    "\n",
    "# step 1: categorize time into blocks\n",
    "def categorize(t):\n",
    "    if t < 600 or t > 2200:\n",
    "        return 'night'\n",
    "    elif 600 <= t < 1000:\n",
    "        return 'morning'\n",
    "    elif 1000 <= t < 1400:\n",
    "        return 'midday'\n",
    "    elif 1400 <= t < 1800:\n",
    "        return 'afternoon'\n",
    "    else:\n",
    "        return 'evening'\n",
    "\n",
    "function = udf(lambda col: categorize(col))\n",
    "total = total.withColumn('departure_window',function(col('G')))\n",
    "# new_df.show()\n",
    "# step 2: count delays vs. total\n",
    "def get_window_delay(df):\n",
    "  '''S: departure delay. T: arrival delay. A: airline'''\n",
    "  result = df.groupBy(\"departure_window\").agg(F.count(F.when(col(\"Q\") > 0, col('departure_window'))).alias(\"departure_delays\"))\n",
    "  return result.orderBy(\"departure_delays\", ascending=False)\n",
    "\n",
    "print(get_window_delay(total).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff4655",
   "metadata": {},
   "source": [
    "### q4:  Which Airports Have The Most Flight Delays? Report by full name, (e.g., Newark Liberty International, not EWR, when the airport code EWR is provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c02ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 137:>                (0 + 2) / 2][Stage 139:>                (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+---+----------------+------------+\n",
      "|                   D|arrival_delays|  C|departure_delays|total_delays|\n",
      "+--------------------+--------------+---+----------------+------------+\n",
      "|Dallas-Fort Worth...|         11848|DFW|           14860|       26708|\n",
      "|International Denver|         10994|DEN|           14216|       25210|\n",
      "|      O'Hare Chicago|         10679|ORD|           12543|       23222|\n",
      "|Hartsfield Jackso...|          8884|ATL|           11214|       20098|\n",
      "|   Douglas Charlotte|          7723|CLT|            9714|       17437|\n",
      "|International Sea...|          8760|SEA|            8505|       17265|\n",
      "|McCarran Internat...|          6783|LAS|            8183|       14966|\n",
      "|Los Angeles Inter...|          6883|LAX|            6760|       13643|\n",
      "|Sky Harbor Intern...|          6364|PHX|            6988|       13352|\n",
      "|George Bush Inter...|          5804|IAH|            7547|       13351|\n",
      "|International Oak...|          5575|MCO|            6500|       12075|\n",
      "|Minneapolis-St. P...|          5700|MSP|            5236|       10936|\n",
      "|International San...|          5236|SFO|            4649|        9885|\n",
      "|Logan Internation...|          4910|BOS|            4733|        9643|\n",
      "|  LaGuardia New York|          4739|LGA|            4430|        9169|\n",
      "|Baltimore/Wash. I...|          3639|BWI|            5442|        9081|\n",
      "|Liberty Internati...|          4337|EWR|            4725|        9062|\n",
      "|Reagan National W...|          4416|DCA|            4325|        8741|\n",
      "|International Phi...|          4262|PHL|            4247|        8509|\n",
      "|Metro Wayne Count...|          4204|DTW|            4242|        8446|\n",
      "+--------------------+--------------+---+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# count using airport names\n",
    "def get_airport_delay(df):\n",
    "    '''Q: departure delay. R: arrival delay. C: departure airport. D: arrival airport'''\n",
    "#   result = df.groupBy(\"A\").agg(F.count(F.when(col(\"T\") > 0) | F.when(col('S') > 0), col('A')).alias(\"delays\"))\n",
    "    arrival = df.groupBy(\"D\").agg(F.count(F.when(col(\"R\") > 0, col('D'))).alias(\"arrival_delays\"))\n",
    "    departure = df.groupBy(\"C\").agg(F.count(F.when(col(\"Q\") > 0, col('C'))).alias(\"departure_delays\"))\n",
    "    result = arrival.join(departure, arrival.D == departure.C, \"inner\").drop(departure.C)\n",
    "    function = udf(lambda col1, col2 : col1+col2, IntegerType())\n",
    "    result = result.withColumn('total_delays',function(col('arrival_delays'),col('departure_delays')))\n",
    "    df_replaced = result.na.replace(airport_codes, subset=[\"D\"])\n",
    "    return df_replaced.orderBy(\"total_delays\", ascending=False)\n",
    "  # result.show()\n",
    "\n",
    "print(get_airport_delay(total).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576a903",
   "metadata": {},
   "source": [
    "### q5: What Are the Top 5 Busiest Airports in the US. Report by full name, (e.g., Newark Liberty International, not EWR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72629281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 119:>                (0 + 2) / 2][Stage 121:>                (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---------------+-----------+\n",
      "|  D|arrival_count|  C|departure_count|total_count|\n",
      "+---+-------------+---+---------------+-----------+\n",
      "|ATL|        29397|ATL|          29403|      58800|\n",
      "|DFW|        27866|DFW|          27871|      55737|\n",
      "|ORD|        27594|ORD|          27594|      55188|\n",
      "|DEN|        27576|DEN|          27585|      55161|\n",
      "|CLT|        21626|CLT|          21626|      43252|\n",
      "|SEA|        17253|SEA|          17248|      34501|\n",
      "|LAX|        16816|LAX|          16815|      33631|\n",
      "|LAS|        15804|LAS|          15806|      31610|\n",
      "|PHX|        15403|PHX|          15407|      30810|\n",
      "|IAH|        15016|IAH|          15014|      30030|\n",
      "|LGA|        13579|LGA|          13581|      27160|\n",
      "|MCO|        13179|MCO|          13175|      26354|\n",
      "|BOS|        12674|BOS|          12672|      25346|\n",
      "|EWR|        11952|EWR|          11949|      23901|\n",
      "|DCA|        11750|DCA|          11746|      23496|\n",
      "|DTW|        11535|DTW|          11537|      23072|\n",
      "|MSP|        11413|MSP|          11411|      22824|\n",
      "|PHL|        11150|PHL|          11145|      22295|\n",
      "|JFK|        10460|JFK|          10456|      20916|\n",
      "|SFO|        10389|SFO|          10382|      20771|\n",
      "+---+-------------+---+---------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# count using airport names\n",
    "def get_airport_num(df):\n",
    "    '''C: departure airport. D: arrival airport'''\n",
    "    departure = df.groupBy(\"C\").agg(F.count(\"C\").alias(\"departure_count\"))\n",
    "    arrival = df.groupBy(\"D\").agg(F.count(\"D\").alias(\"arrival_count\"))\n",
    "\n",
    "    result = arrival.join(departure, arrival.D == departure.C, \"inner\").drop(departure.C)\n",
    "    function = udf(lambda col1, col2 : col1+col2, IntegerType())\n",
    "    result = result.withColumn('total_count',function(col('arrival_count'),col('departure_count')))\n",
    "    df_replaced = result.na.replace(airport_codes, subset=[\"D\"])\n",
    "    return df_replaced.orderBy(\"total_count\", ascending=False)\n",
    "  # result.show()\n",
    "print(get_airport_num(total).show())\n",
    "# print(get_airport_delay(total).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24636ccf",
   "metadata": {},
   "source": [
    "## Part 3 Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a19382",
   "metadata": {},
   "source": [
    "### q1: read and clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe192df",
   "metadata": {},
   "source": [
    "cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "401b8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import string\n",
    "stopwords_list = requests.get(\"https://gist.githubusercontent.com/rg089/35e00abf8941d72d419224cfd5b5925d/raw/12d899b70156fd0041fa9778d657330b024b959c/stopwords.txt\").content\n",
    "stopwords = list(set(stopwords_list.decode().splitlines()))\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    list_ = re.sub(r\"[^a-zA-Z0-9]\", \" \", words.lower()).split()\n",
    "    return [itm for itm in list_ if itm not in stopwords]\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('[\\d\\n]', ' ', text)\n",
    "    return ' '.join(remove_stopwords(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90bb92c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE_THOUSAND-AND-SECOND_TALE_OF_SCHEHERAZADE', 'THE_ISLAND_OF_THE_FAY', 'MESMERIC_REVELATION', 'A_DESCENT_INTO_THE_MAELSTROM', 'VON_KEMPELEN_AND_HIS_DISCOVERY', 'THE_DOMAIN_OF_ARNHEIM', 'THE_FALL_OF_THE_HOUSE_OF_USHER', 'THE_PIT_AND_THE_PENDULUM', 'THE_BLACK_CAT', 'SILENCE-A_FABLE', 'THE_IMP_OF_THE_PERVERSE', 'THE_FACTS_IN_THE_CASE_OF_M._VALDEMAR', 'THE_PURLOINED_LETTER', 'THE_PREMATURE_BURIAL', 'ELEONORA', 'THE_MASQUE_OF_THE_RED_DEATH', 'THE_ASSIGNATION', 'BERENICE', 'THE_CASK_OF_AMONTILLADO', 'LANDORS_COTTAGE', 'WILLIAM_WILSON']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "all_files = os.listdir(\"poe-stories/\") \n",
    "print(all_files)\n",
    "\n",
    "# reading and cleaning files, then saving them to a list\n",
    "cleaned = []\n",
    "for file in all_files:\n",
    "    \n",
    "    f = open(\"poe-stories/\"+file,'r')\n",
    "    text = f.read().strip()\n",
    "    cleaned.append(clean_text(text))\n",
    "    \n",
    "print(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee3d228",
   "metadata": {},
   "source": [
    "### q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017ac1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nanxiliu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nanxiliu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# try it on the first story \n",
    "sent_text = nltk.sent_tokenize(cleaned[0]) # this gives us a list of sentences\n",
    "# now loop over each sentence and tokenize it separately\n",
    "all_tagged = [nltk.pos_tag(nltk.word_tokenize(sent)) for sent in sent_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd8c0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('truth', 'NN'), ('stranger', 'NN'), ('fiction', 'NN'), ('occasion', 'NN'), ('oriental', 'JJ'), ('investigations', 'NNS'), ('consult', 'VBP'), ('tellmenow', 'JJ'), ('isits', 'NNS'), ('ornot', 'VBP'), ('work', 'NN'), ('zohar', 'NN'), ('simeon', 'NN'), ('jochaides', 'NNS'), ('scarcely', 'RB'), ('europe', 'VBP'), ('quoted', 'VBN'), ('knowledge', 'NN'), ('american', 'JJ'), ('author', 'NN'), ('curiosities', 'NNS'), ('american', 'JJ'), ('literature', 'NN'), ('occasion', 'NN'), ('turn', 'NN'), ('mentioned', 'VBD'), ('remarkable', 'JJ'), ('work', 'NN'), ('astonished', 'VBD'), ('discover', 'RB'), ('literary', 'JJ'), ('hitherto', 'NN'), ('strangely', 'RB'), ('error', 'JJ'), ('respecting', 'VBG'), ('fate', 'NN'), ('vizier', 'NN'), ('daughter', 'NN'), ('scheherazade', 'NN'), ('fate', 'NN'), ('depicted', 'VBD'), ('arabian', 'JJ'), ('nights', 'NNS'), ('nouement', 'JJ'), ('altogether', 'RB'), ('inaccurate', 'JJ'), ('blame', 'NN'), ('farther', 'RBR'), ('interesting', 'JJ'), ('topic', 'NN'), ('refer', 'VBP'), ('inquisitive', 'JJ'), ('reader', 'NN'), ('isits', 'NNS'), ('ornot', 'VBP'), ('pardoned', 'VBN'), ('summary', 'JJ'), ('discovered', 'VBD'), ('remembered', 'JJ'), ('usual', 'JJ'), ('version', 'NN'), ('tales', 'NNS'), ('monarch', 'VBP'), ('good', 'JJ'), ('jealous', 'JJ'), ('queen', 'NN'), ('puts', 'VBZ'), ('death', 'NN'), ('vow', 'NN'), ('beard', 'NN'), ('prophet', 'NN'), ('espouse', 'NN'), ('night', 'NN'), ('beautiful', 'JJ'), ('maiden', 'JJ'), ('dominions', 'NNS'), ('morning', 'NN'), ('deliver', 'NN'), ('executioner', 'NN'), ('fulfilled', 'VBD'), ('vow', 'CD'), ('years', 'NNS'), ('letter', 'NN'), ('religious', 'JJ'), ('punctuality', 'NN'), ('method', 'NN'), ('conferred', 'VBD'), ('great', 'JJ'), ('credit', 'NN'), ('man', 'NN'), ('devout', 'IN'), ('feeling', 'VBG'), ('excellent', 'JJ'), ('sense', 'NN'), ('interrupted', 'VBD'), ('afternoon', 'NN'), ('doubt', 'NN'), ('prayers', 'NNS'), ('visit', 'VBP'), ('grand', 'JJ'), ('vizier', 'NN'), ('daughter', 'NN'), ('appears', 'VBZ'), ('occurred', 'VBD'), ('idea', 'NN'), ('scheherazade', 'NN'), ('idea', 'NN'), ('redeem', 'VBP'), ('land', 'NN'), ('depopulating', 'VBG'), ('tax', 'NN'), ('beauty', 'NN'), ('perish', 'NN'), ('approved', 'VBD'), ('fashion', 'NN'), ('heroines', 'NNS'), ('attempt', 'NN'), ('leap', 'JJ'), ('year', 'NN'), ('sacrifice', 'RB'), ('meritorious', 'JJ'), ('deputes', 'NNS'), ('father', 'RB'), ('grand', 'JJ'), ('vizier', 'NN'), ('offer', 'NN'), ('king', 'VBG'), ('hand', 'NN'), ('hand', 'NN'), ('king', 'VBG'), ('eagerly', 'RB'), ('accepts', 'NNS'), ('intended', 'VBD'), ('events', 'NNS'), ('matter', 'JJ'), ('day', 'NN'), ('day', 'NN'), ('fear', 'VB'), ('vizier', 'IN'), ('accepting', 'VBG'), ('parties', 'NNS'), ('distinctly', 'RB'), ('understand', 'VBP'), ('grand', 'JJ'), ('vizier', 'JJR'), ('grand', 'JJ'), ('vizier', 'JJR'), ('slightest', 'JJS'), ('design', 'NN'), ('iota', 'NN'), ('vow', 'NN'), ('privileges', 'NNS'), ('fair', 'VBP'), ('scheherazade', 'RB'), ('insisted', 'JJ'), ('marrying', 'VBG'), ('king', 'NN'), ('marry', 'NN'), ('father', 'RBR'), ('excellent', 'JJ'), ('advice', 'NN'), ('thing', 'NN'), ('kind', 'NN'), ('marry', 'NN'), ('nill', 'RB'), ('beautiful', 'JJ'), ('black', 'JJ'), ('eyes', 'NNS'), ('open', 'JJ'), ('nature', 'NN'), ('case', 'NN'), ('politic', 'JJ'), ('damsel', 'NN'), ('reading', 'VBG'), ('machiavelli', 'JJ'), ('doubt', 'NN'), ('ingenious', 'JJ'), ('plot', 'NN'), ('mind', 'NN'), ('night', 'NN'), ('wedding', 'VBG'), ('contrived', 'VBD'), ('forget', 'RB'), ('specious', 'JJ'), ('pretence', 'NN'), ('sister', 'NN'), ('occupy', 'VBP'), ('couch', 'JJ'), ('royal', 'NN'), ('pair', 'NN'), ('admit', 'VBP'), ('easy', 'JJ'), ('conversation', 'NN'), ('bed', 'VBD'), ('bed', 'JJ'), ('cock', 'NN'), ('crowing', 'VBG'), ('care', 'NN'), ('awaken', 'RB'), ('good', 'JJ'), ('monarch', 'NN'), ('husband', 'NN'), ('bore', 'VBD'), ('worse', 'JJR'), ('intended', 'VBN'), ('wring', 'VBG'), ('neck', 'NN'), ('morrow', 'NN'), ('managed', 'VBD'), ('awaken', 'JJ'), ('account', 'NN'), ('capital', 'NN'), ('conscience', 'NN'), ('easy', 'JJ'), ('digestion', 'NN'), ('slept', 'VBD'), ('profound', 'JJ'), ('story', 'NN'), ('rat', 'NN'), ('black', 'JJ'), ('cat', 'NN'), ('narrating', 'VBG'), ('undertone', 'JJ'), ('sister', 'NN'), ('day', 'NN'), ('broke', 'VBD'), ('happened', 'VBD'), ('history', 'NN'), ('altogether', 'RB'), ('finished', 'VBD'), ('scheherazade', 'JJ'), ('nature', 'NN'), ('things', 'NNS'), ('finish', 'JJ'), ('high', 'JJ'), ('time', 'NN'), ('bowstrung', 'JJ'), ('thing', 'NN'), ('pleasant', 'JJ'), ('hanging', 'VBG'), ('trifle', 'JJ'), ('genteel', 'NN'), ('king', 'VBG'), ('curiosity', 'NN'), ('prevailing', 'VBG'), ('sound', 'JJ'), ('religious', 'JJ'), ('principles', 'NNS'), ('induced', 'VBD'), ('postpone', 'JJ'), ('fulfilment', 'JJ'), ('vow', 'NN'), ('morning', 'NN'), ('purpose', 'JJ'), ('hope', 'NN'), ('hearing', 'VBG'), ('night', 'NN'), ('fared', 'VBD'), ('black', 'JJ'), ('cat', 'NN'), ('black', 'JJ'), ('cat', 'NN'), ('rat', 'NN'), ('night', 'NN'), ('arrived', 'VBD'), ('lady', 'JJ'), ('scheherazade', 'NN'), ('finishing', 'VBG'), ('stroke', 'VBD'), ('black', 'JJ'), ('cat', 'NN'), ('rat', 'NN'), ('rat', 'NN'), ('blue', 'JJ'), ('knew', 'VBD'), ('deep', 'JJ'), ('intricacies', 'NNS'), ('narration', 'VBP'), ('reference', 'NN'), ('altogether', 'RB'), ('mistaken', 'JJ'), ('pink', 'JJ'), ('horse', 'NN'), ('green', 'JJ'), ('wings', 'NNS'), ('violent', 'JJ'), ('manner', 'NN'), ('clockwork', 'NN'), ('wound', 'NN'), ('indigo', 'NN'), ('key', 'JJ'), ('history', 'NN'), ('king', 'VBG'), ('profoundly', 'RB'), ('interested', 'JJ'), ('day', 'NN'), ('broke', 'VBD'), ('conclusion', 'NN'), ('notwithstanding', 'VBG'), ('queen', 'JJ'), ('endeavors', 'NNS'), ('time', 'NN'), ('bowstringing', 'VBG'), ('resource', 'NN'), ('postpone', 'NN'), ('ceremony', 'NN'), ('hours', 'NNS'), ('night', 'NN'), ('happened', 'VBD'), ('accident', 'JJ'), ('result', 'NN'), ('good', 'JJ'), ('monarch', 'NN'), ('unavoidably', 'RB'), ('deprived', 'VBD'), ('opportunity', 'NN'), ('vow', 'NN'), ('period', 'NN'), ('nights', 'NNS'), ('forgets', 'VBZ'), ('altogether', 'RB'), ('expiration', 'JJ'), ('time', 'NN'), ('absolved', 'VBD'), ('regular', 'JJ'), ('probable', 'JJ'), ('breaks', 'NNS'), ('outright', 'MD'), ('head', 'VB'), ('father', 'NN'), ('confessor', 'NN'), ('events', 'NNS'), ('scheherazade', 'VBD'), ('lineally', 'RB'), ('descended', 'VBN'), ('eve', 'NN'), ('fell', 'VBD'), ('heir', 'PRP$'), ('baskets', 'NNS'), ('talk', 'VBP'), ('lady', 'JJ'), ('picked', 'VBN'), ('trees', 'NNS'), ('garden', 'VBP'), ('eden', 'RB'), ('scheherazade', 'VBN'), ('finally', 'RB'), ('triumphed', 'VBN'), ('tariff', 'NN'), ('beauty', 'NN'), ('repealed', 'VBD'), ('conclusion', 'NN'), ('story', 'NN'), ('record', 'NN'), ('doubt', 'NN'), ('excessively', 'RB'), ('proper', 'JJ'), ('pleasant', 'JJ'), ('alas', 'NNS'), ('great', 'JJ'), ('pleasant', 'JJ'), ('things', 'NNS'), ('pleasant', 'VBP'), ('true', 'JJ'), ('indebted', 'JJ'), ('altogether', 'RB'), ('isits', 'VBZ'), ('ornot', 'RP'), ('correcting', 'VBG'), ('error', 'NN'), ('mieux', 'NN'), ('french', 'JJ'), ('proverb', 'NN'), ('ennemi', 'NN'), ('bien', 'NN'), ('mentioning', 'VBG'), ('scheherazade', 'NN'), ('inherited', 'VBN'), ('baskets', 'NNS'), ('talk', 'VBP'), ('compound', 'NN'), ('amounted', 'VBD'), ('seventy', 'JJ'), ('dear', 'JJ'), ('sister', 'NN'), ('night', 'NN'), ('quote', 'NN'), ('language', 'NN'), ('isits', 'VBZ'), ('ornot', 'JJ'), ('point', 'NN'), ('verbatim', 'NN'), ('dear', 'VBP'), ('sister', 'NN'), ('difficulty', 'NN'), ('bowstring', 'VBG'), ('blown', 'RB'), ('odious', 'JJ'), ('tax', 'NN'), ('happily', 'RB'), ('repealed', 'VBD'), ('feel', 'VB'), ('guilty', 'JJ'), ('great', 'JJ'), ('indiscretion', 'NN'), ('withholding', 'VBG'), ('king', 'VBG'), ('snores', 'NNS'), ('thing', 'NN'), ('gentleman', 'JJ'), ('conclusion', 'NN'), ('sinbad', 'NN'), ('sailor', 'NN'), ('person', 'NN'), ('numerous', 'JJ'), ('interesting', 'JJ'), ('adventures', 'NNS'), ('truth', 'VBP'), ('felt', 'VBD'), ('sleepy', 'JJ'), ('night', 'NN'), ('narration', 'NN'), ('seduced', 'VBD'), ('cutting', 'VBG'), ('short', 'RB'), ('grievous', 'JJ'), ('piece', 'NN'), ('misconduct', 'NN'), ('trust', 'NN'), ('allah', 'RB'), ('forgive', 'JJ'), ('late', 'JJ'), ('remedy', 'NN'), ('great', 'JJ'), ('neglect', 'JJ'), ('king', 'NN'), ('pinch', 'NN'), ('order', 'NN'), ('wake', 'NN'), ('making', 'VBG'), ('horrible', 'JJ'), ('noise', 'NN'), ('forthwith', 'NN'), ('entertain', 'NN'), ('pleases', 'NNS'), ('sequel', 'VBP'), ('remarkable', 'JJ'), ('story', 'NN'), ('sister', 'NN'), ('scheherazade', 'VBD'), ('isits', 'NNS'), ('ornot', 'NNS'), ('expressed', 'VBD'), ('intensity', 'NN'), ('gratification', 'NN'), ('king', 'VBG'), ('pinched', 'JJ'), ('length', 'NN'), ('ceased', 'VBD'), ('snoring', 'VBG'), ('finally', 'RB'), ('hum', 'JJ'), ('hoo', 'NN'), ('queen', 'NN'), ('understanding', 'VBG'), ('doubt', 'NN'), ('arabic', 'JJ'), ('signify', 'NN'), ('attention', 'NN'), ('snore', 'NN'), ('queen', 'JJ'), ('arranged', 'VBD'), ('matters', 'NNS'), ('satisfaction', 'NN'), ('entered', 'VBD'), ('history', 'NN'), ('sinbad', 'NN'), ('sailor', 'NN'), ('length', 'NN'), ('age', 'NN'), ('sinbad', 'NN'), ('retailed', 'VBD'), ('scheherazade', 'JJ'), ('length', 'NN'), ('age', 'NN'), ('enjoying', 'VBG'), ('years', 'NNS'), ('tranquillity', 'NN'), ('possessed', 'VBD'), ('desire', 'NN'), ('visiting', 'VBG'), ('foreign', 'JJ'), ('countries', 'NNS'), ('day', 'NN'), ('acquainting', 'VBG'), ('family', 'NN'), ('design', 'NN'), ('packed', 'VBD'), ('bundles', 'NNS'), ('merchandise', 'NN'), ('precious', 'JJ'), ('bulky', 'NN'), ('engaging', 'VBG'), ('porter', 'NN'), ('carry', 'VBP'), ('sea', 'NN'), ('shore', 'NN'), ('await', 'NN'), ('arrival', 'JJ'), ('chance', 'NN'), ('vessel', 'NN'), ('convey', 'NN'), ('kingdom', 'NN'), ('region', 'NN'), ('explored', 'VBD'), ('deposited', 'VBN'), ('packages', 'NNS'), ('sands', 'NNS'), ('sat', 'VBD'), ('beneath', 'NN'), ('trees', 'NNS'), ('looked', 'VBD'), ('ocean', 'JJ'), ('hope', 'NN'), ('perceiving', 'VBG'), ('ship', 'JJ'), ('hours', 'NNS'), ('length', 'VBP'), ('fancied', 'VBN'), ('hear', 'JJ'), ('singular', 'JJ'), ('buzzing', 'VBG'), ('humming', 'VBG'), ('sound', 'JJ'), ('porter', 'NN'), ('listening', 'VBG'), ('awhile', 'RB'), ('declared', 'VBN'), ('distinguish', 'NN'), ('presently', 'RB'), ('grew', 'VBD'), ('louder', 'JJR'), ('louder', 'NN'), ('doubt', 'NN'), ('object', 'NN'), ('caused', 'VBD'), ('approaching', 'VBG'), ('length', 'NN'), ('edge', 'NN'), ('horizon', 'NN'), ('discovered', 'VBD'), ('black', 'JJ'), ('speck', 'NN'), ('rapidly', 'RB'), ('increased', 'VBD'), ('size', 'NN'), ('vast', 'NN'), ('monster', 'NN'), ('swimming', 'VBG'), ('great', 'JJ'), ('body', 'NN'), ('surface', 'NN'), ('sea', 'NN'), ('inconceivable', 'JJ'), ('swiftness', 'NN'), ('throwing', 'VBG'), ('huge', 'JJ'), ('waves', 'NNS'), ('foam', 'VBP'), ('breast', 'IN'), ('illuminating', 'VBG'), ('sea', 'NN'), ('passed', 'VBD'), ('long', 'RB'), ('extended', 'VBN'), ('distance', 'NN'), ('thing', 'NN'), ('drew', 'VBD'), ('distinctly', 'RB'), ('length', 'JJ'), ('equal', 'JJ'), ('loftiest', 'JJS'), ('trees', 'NNS'), ('grow', 'VBP'), ('wide', 'JJ'), ('great', 'JJ'), ('hall', 'JJ'), ('audience', 'NN'), ('palace', 'NN'), ('sublime', 'JJ'), ('munificent', 'NN'), ('caliphs', 'NN'), ('body', 'NN'), ('ordinary', 'JJ'), ('fishes', 'NNS'), ('solid', 'JJ'), ('rock', 'NN'), ('jetty', 'NN'), ('blackness', 'NN'), ('portion', 'NN'), ('floated', 'VBD'), ('water', 'NN'), ('exception', 'NN'), ('narrow', 'JJ'), ('blood', 'NN'), ('red', 'JJ'), ('streak', 'NN'), ('completely', 'RB'), ('begirdled', 'VBD'), ('belly', 'RB'), ('floated', 'VBN'), ('beneath', 'NN'), ('surface', 'NN'), ('glimpse', 'NN'), ('monster', 'NN'), ('rose', 'VBD'), ('fell', 'VBD'), ('billows', 'NNS'), ('covered', 'VBN'), ('metallic', 'JJ'), ('scales', 'NNS'), ('color', 'NN'), ('moon', 'NN'), ('misty', 'NN'), ('weather', 'NN'), ('flat', 'JJ'), ('white', 'JJ'), ('extended', 'VBN'), ('upwards', 'NNS'), ('spines', 'NNS'), ('half', 'NN'), ('length', 'NN'), ('body', 'NN'), ('horrible', 'JJ'), ('creature', 'NN'), ('mouth', 'NN'), ('perceive', 'JJ'), ('deficiency', 'NN'), ('provided', 'VBD'), ('score', 'RB'), ('eyes', 'NNS'), ('protruded', 'VBD'), ('sockets', 'NNS'), ('green', 'JJ'), ('dragon', 'NN'), ('fly', 'NN'), ('arranged', 'VBD'), ('body', 'NN'), ('rows', 'NNS'), ('parallel', 'VBP'), ('blood', 'NN'), ('red', 'JJ'), ('streak', 'NN'), ('answer', 'NN'), ('purpose', 'NN'), ('eyebrow', 'NN'), ('dreadful', 'JJ'), ('eyes', 'NNS'), ('larger', 'JJR'), ('appearance', 'NN'), ('solid', 'JJ'), ('gold', 'NN'), ('beast', 'NN'), ('approached', 'VBD'), ('greatest', 'JJS'), ('rapidity', 'NN'), ('moved', 'VBD'), ('altogether', 'RB'), ('necromancy', 'NN'), ('fins', 'NNS'), ('fish', 'JJ'), ('web', 'JJ'), ('feet', 'NNS'), ('duck', 'JJ'), ('wings', 'NNS'), ('seashell', 'VBP'), ('blown', 'JJ'), ('manner', 'NN'), ('vessel', 'IN'), ('writhe', 'JJ'), ('forward', 'NN'), ('eels', 'NNS'), ('head', 'VBP'), ('tail', 'NN'), ('shaped', 'VBN'), ('precisely', 'RB'), ('alike', 'IN'), ('small', 'JJ'), ('holes', 'NNS'), ('served', 'VBD'), ('nostrils', 'NNS'), ('monster', 'NN'), ('puffed', 'VBP'), ('thick', 'JJ'), ('breath', 'NN'), ('prodigious', 'JJ'), ('violence', 'NN'), ('shrieking', 'VBG'), ('disagreeable', 'JJ'), ('noise', 'NN'), ('terror', 'NN'), ('beholding', 'VBG'), ('hideous', 'JJ'), ('thing', 'NN'), ('great', 'JJ'), ('surpassed', 'JJ'), ('astonishment', 'NN'), ('nearer', 'NN'), ('perceived', 'VBD'), ('creature', 'NN'), ('vast', 'JJ'), ('number', 'NN'), ('animals', 'NNS'), ('size', 'NN'), ('shape', 'NN'), ('men', 'NNS'), ('altogether', 'RB'), ('resembling', 'VBG'), ('wore', 'RBR'), ('garments', 'NNS'), ('men', 'NNS'), ('supplied', 'VBD'), ('nature', 'JJ'), ('doubt', 'NN'), ('ugly', 'RB'), ('uncomfortable', 'JJ'), ('covering', 'VBG'), ('good', 'JJ'), ('deal', 'NN'), ('cloth', 'NN'), ('fitting', 'VBG'), ('tight', 'JJ'), ('skin', 'NN'), ('render', 'NN'), ('poor', 'JJ'), ('wretches', 'NNS'), ('laughably', 'RB'), ('awkward', 'RB'), ('severe', 'JJ'), ('pain', 'NN'), ('tips', 'NNS'), ('heads', 'NNS'), ('square', 'VBP'), ('boxes', 'NNS'), ('sight', 'VBD'), ('thought', 'RB'), ('intended', 'VBN'), ('answer', 'NN'), ('turbans', 'NNS'), ('discovered', 'VBD'), ('excessively', 'RB'), ('heavy', 'JJ'), ('solid', 'NNS'), ('concluded', 'VBD'), ('contrivances', 'NNS'), ('designed', 'VBN'), ('great', 'JJ'), ('weight', 'NN'), ('heads', 'NNS'), ('animals', 'NNS'), ('steady', 'JJ'), ('safe', 'JJ'), ('shoulders', 'NNS'), ('necks', 'NNS'), ('creatures', 'NNS'), ('fastened', 'VBD'), ('black', 'JJ'), ('collars', 'NNS'), ('badges', 'NNS'), ('servitude', 'VBP'), ('doubt', 'JJ'), ('dogs', 'NNS'), ('wider', 'RBR'), ('infinitely', 'RB'), ('stiffer', 'VBP'), ('impossible', 'JJ'), ('poor', 'JJ'), ('victims', 'NNS'), ('heads', 'NNS'), ('direction', 'NN'), ('moving', 'VBG'), ('body', 'NN'), ('time', 'NN'), ('doomed', 'VBN'), ('perpetual', 'JJ'), ('contemplation', 'NN'), ('noses', 'NNS'), ('view', 'VBP'), ('puggish', 'JJ'), ('snubby', 'NN'), ('wonderful', 'NN'), ('positively', 'RB'), ('awful', 'JJ'), ('degree', 'NN'), ('monster', 'NN'), ('reached', 'VBD'), ('shore', 'RB'), ('stood', 'JJ'), ('suddenly', 'RB'), ('pushed', 'JJ'), ('eyes', 'NNS'), ('great', 'JJ'), ('extent', 'NN'), ('emitted', 'VBD'), ('terrible', 'JJ'), ('flash', 'NN'), ('accompanied', 'VBD'), ('dense', 'JJ'), ('cloud', 'NN'), ('smoke', 'VBD'), ('noise', 'RB'), ('compare', 'JJ'), ('thunder', 'NN'), ('smoke', 'NN'), ('cleared', 'VBD'), ('odd', 'JJ'), ('man', 'NN'), ('animals', 'NNS'), ('standing', 'VBG'), ('head', 'NN'), ('large', 'JJ'), ('beast', 'NN'), ('trumpet', 'NN'), ('hand', 'NN'), ('putting', 'VBG'), ('mouth', 'NN'), ('presently', 'RB'), ('addressed', 'VBD'), ('loud', 'JJ'), ('harsh', 'NN'), ('disagreeable', 'JJ'), ('accents', 'NNS'), ('mistaken', 'JJ'), ('language', 'NN'), ('altogether', 'RB'), ('nose', 'RB'), ('evidently', 'RB'), ('spoken', 'JJ'), ('loss', 'NN'), ('reply', 'NN'), ('manner', 'NN'), ('understand', 'VBP'), ('difficulty', 'NN'), ('turned', 'VBD'), ('porter', 'RB'), ('swooning', 'VBG'), ('affright', 'RB'), ('demanded', 'VBN'), ('opinion', 'NN'), ('species', 'NNS'), ('monster', 'RBR'), ('wanted', 'VBD'), ('kind', 'NN'), ('creatures', 'NNS'), ('swarmed', 'VBD'), ('porter', 'RB'), ('replied', 'VBN'), ('trepidation', 'NN'), ('heard', 'NN'), ('sea', 'NN'), ('beast', 'NN'), ('cruel', 'NN'), ('demon', 'NN'), ('bowels', 'NNS'), ('sulphur', 'VBP'), ('blood', 'NN'), ('created', 'VBN'), ('evil', 'JJ'), ('genii', 'NN'), ('inflicting', 'VBG'), ('misery', 'NN'), ('mankind', 'NN'), ('things', 'NNS'), ('vermin', 'VBP'), ('infest', 'JJS'), ('cats', 'NNS'), ('dogs', 'NNS'), ('larger', 'JJR'), ('savage', 'NN'), ('vermin', 'NN'), ('evil', 'JJ'), ('torture', 'NN'), ('caused', 'VBD'), ('beast', 'JJ'), ('nibbling', 'JJ'), ('stingings', 'NNS'), ('goaded', 'VBD'), ('degree', 'JJ'), ('wrath', 'NN'), ('requisite', 'NN'), ('roar', 'NN'), ('commit', 'NN'), ('ill', 'NN'), ('fulfil', 'VBZ'), ('vengeful', 'JJ'), ('malicious', 'JJ'), ('designs', 'NNS'), ('wicked', 'VBD'), ('genii', 'JJ'), ('account', 'NN'), ('determined', 'VBD'), ('heels', 'NNS'), ('speed', 'NN'), ('hills', 'NNS'), ('porter', 'VBP'), ('equally', 'RB'), ('fast', 'JJ'), ('opposite', 'JJ'), ('direction', 'NN'), ('finally', 'RB'), ('escape', 'JJ'), ('bundles', 'NNS'), ('doubt', 'VBP'), ('excellent', 'JJ'), ('care', 'NN'), ('point', 'NN'), ('determine', 'NN'), ('remember', 'VB'), ('beheld', 'VBN'), ('hotly', 'RB'), ('pursued', 'VBN'), ('swarm', 'JJ'), ('men', 'NNS'), ('vermin', 'VBP'), ('shore', 'NN'), ('boats', 'NNS'), ('overtaken', 'VBP'), ('bound', 'JJ'), ('hand', 'NN'), ('foot', 'NN'), ('conveyed', 'VBD'), ('beast', 'NN'), ('swam', 'NN'), ('middle', 'JJ'), ('sea', 'NN'), ('bitterly', 'RB'), ('repented', 'VBN'), ('folly', 'RB'), ('quitting', 'VBG'), ('comfortable', 'JJ'), ('peril', 'JJ'), ('life', 'NN'), ('adventures', 'NNS'), ('regret', 'VBP'), ('useless', 'JJ'), ('condition', 'NN'), ('exerted', 'VBD'), ('secure', 'NN'), ('goodwill', 'NN'), ('man', 'NN'), ('animal', 'NN'), ('owned', 'VBD'), ('trumpet', 'NN'), ('appeared', 'VBD'), ('exercise', 'JJ'), ('authority', 'NN'), ('fellows', 'NNS'), ('succeeded', 'VBD'), ('endeavor', 'NN'), ('days', 'NNS'), ('creature', 'NN'), ('bestowed', 'VBD'), ('tokens', 'NNS'), ('favor', 'NN'), ('trouble', 'NN'), ('teaching', 'VBG'), ('rudiments', 'NNS'), ('vain', 'VBP'), ('denominate', 'JJ'), ('language', 'NN'), ('length', 'NN'), ('enabled', 'VBD'), ('converse', 'JJ'), ('comprehend', 'NN'), ('ardent', 'NN'), ('desire', 'NN'), ('washish', 'JJ'), ('squashish', 'JJ'), ('squeak', 'NN'), ('sinbad', 'NN'), ('hey', 'NN'), ('diddle', 'VBP'), ('diddle', 'JJ'), ('grunt', 'NN'), ('unt', 'NN'), ('grumble', 'JJ'), ('hiss', 'JJ'), ('fiss', 'JJ'), ('whiss', 'JJ'), ('day', 'NN'), ('dinner', 'NN'), ('beg', 'NN'), ('pardons', 'NNS'), ('forgotten', 'VBP'), ('majesty', 'JJ'), ('conversant', 'NN'), ('dialect', 'NN'), ('cock', 'NN'), ('neighs', 'NNS'), ('man', 'NN'), ('animals', 'NNS'), ('called', 'VBD'), ('presume', 'JJ'), ('language', 'NN'), ('formed', 'VBD'), ('connecting', 'VBG'), ('link', 'NN'), ('horse', 'NN'), ('rooster', 'NN'), ('permission', 'NN'), ('translate', 'NN'), ('washish', 'JJ'), ('squashish', 'JJ'), ('happy', 'JJ'), ('dear', 'NN'), ('sinbad', 'NN'), ('excellent', 'JJ'), ('fellow', 'JJ'), ('thing', 'NN'), ('called', 'VBN'), ('circumnavigating', 'VBG'), ('globe', 'NN'), ('desirous', 'JJ'), ('strain', 'NN'), ('point', 'NN'), ('free', 'JJ'), ('passage', 'NN'), ('beast', 'NN'), ('lady', 'NN'), ('scheherazade', 'NN'), ('proceeded', 'VBD'), ('relates', 'VBZ'), ('isits', 'NNS'), ('ornot', 'RP'), ('king', 'VBG'), ('turned', 'JJ'), ('left', 'JJ'), ('fact', 'NN'), ('surprising', 'JJ'), ('dear', 'NN'), ('queen', 'JJ'), ('hitherto', 'NN'), ('adventures', 'NNS'), ('sinbad', 'VBP'), ('exceedingly', 'RB'), ('entertaining', 'JJ'), ('strange', 'JJ'), ('king', 'NN'), ('expressed', 'VBN'), ('told', 'VBD'), ('fair', 'JJ'), ('scheherazade', 'NN'), ('resumed', 'VBD'), ('history', 'NN'), ('sinbad', 'NN'), ('manner', 'NN'), ('narrative', 'JJ'), ('thanked', 'VBD'), ('man', 'NN'), ('animal', 'NN'), ('kindness', 'NN'), ('beast', 'NN'), ('swam', 'JJ'), ('prodigious', 'JJ'), ('rate', 'NN'), ('ocean', 'JJ'), ('surface', 'NN'), ('flat', 'JJ'), ('round', 'NN'), ('pomegranate', 'NN'), ('hill', 'NN'), ('hill', 'JJ'), ('time', 'NN'), ('singular', 'JJ'), ('interrupted', 'VBD'), ('king', 'VBG'), ('true', 'JJ'), ('replied', 'VBN'), ('scheherazade', 'NN'), ('doubts', 'NNS'), ('rejoined', 'VBD'), ('king', 'VBG'), ('pray', 'NN'), ('good', 'JJ'), ('story', 'NN'), ('queen', 'JJ'), ('beast', 'NN'), ('continued', 'VBD'), ('sinbad', 'JJ'), ('caliph', 'NN'), ('swam', 'NN'), ('hill', 'NN'), ('hill', 'VB'), ('length', 'NN'), ('arrived', 'VBN'), ('island', 'NN'), ('hundreds', 'NNS'), ('miles', 'NNS'), ('circumference', 'RB'), ('built', 'VBD'), ('middle', 'JJ'), ('sea', 'NN'), ('colony', 'NN'), ('things', 'NNS'), ('caterpillars', 'NNS'), ('hum', 'VBP'), ('king', 'VBG'), ('leaving', 'VBG'), ('island', 'NN'), ('sinbad', 'NN'), ('scheherazade', 'VBD'), ('understood', 'JJ'), ('notice', 'JJ'), ('husband', 'NN'), ('ill', 'NN'), ('mannered', 'VBN'), ('ejaculation', 'NN'), ('leaving', 'VBG'), ('island', 'NN'), ('forests', 'NNS'), ('solid', 'VBP'), ('stone', 'RB'), ('hard', 'JJ'), ('shivered', 'VBD'), ('pieces', 'NNS'), ('finest', 'JJS'), ('tempered', 'VBN'), ('axes', 'NNS'), ('endeavoured', 'VBD'), ('cut', 'JJ'), ('hum', 'NN'), ('king', 'VBG'), ('scheherazade', 'NN'), ('paying', 'VBG'), ('attention', 'NN'), ('continued', 'VBD'), ('language', 'NN'), ('sinbad', 'NN'), ('passing', 'VBG'), ('island', 'NN'), ('reached', 'VBD'), ('country', 'NN'), ('cave', 'VB'), ('distance', 'NN'), ('thirty', 'NN'), ('miles', 'NNS'), ('bowels', 'NNS'), ('earth', 'NN'), ('contained', 'VBN'), ('greater', 'JJR'), ('number', 'NN'), ('spacious', 'JJ'), ('magnificent', 'JJ'), ('palaces', 'NNS'), ('damascus', 'VBP'), ('bagdad', 'JJ'), ('roofs', 'NN'), ('palaces', 'NNS'), ('hung', 'VBD'), ('myriads', 'NNS'), ('gems', 'VB'), ('diamonds', 'NNS'), ('larger', 'JJR'), ('men', 'NNS'), ('streets', 'VBZ'), ('towers', 'NNS'), ('pyramids', 'NNS'), ('temples', 'NNS'), ('flowed', 'VBD'), ('immense', 'JJ'), ('rivers', 'NNS'), ('black', 'JJ'), ('ebony', 'NN'), ('swarming', 'VBG'), ('fish', 'JJ'), ('eyes', 'NNS'), ('hum', 'VBP'), ('king', 'VBG'), ('swam', 'NN'), ('region', 'NN'), ('sea', 'NN'), ('lofty', 'NN'), ('mountain', 'NN'), ('sides', 'NNS'), ('streamed', 'VBD'), ('torrents', 'NNS'), ('melted', 'VBN'), ('metal', 'JJ'), ('miles', 'NNS'), ('wide', 'JJ'), ('miles', 'NNS'), ('long', 'RB'), ('abyss', 'JJ'), ('summit', 'NN'), ('issued', 'VBD'), ('vast', 'JJ'), ('quantity', 'NN'), ('ashes', 'NNS'), ('sun', 'RB'), ('blotted', 'VBD'), ('heavens', 'NNS'), ('darker', 'NN'), ('darkest', 'JJS'), ('midnight', 'NN'), ('distance', 'NN'), ('fifty', 'JJ'), ('miles', 'NNS'), ('mountain', 'RB'), ('impossible', 'JJ'), ('whitest', 'JJS'), ('object', 'NN'), ('close', 'JJ'), ('held', 'VBD'), ('eyes', 'NNS'), ('hum', 'NN'), ('king', 'VBG'), ('quitting', 'VBG'), ('coast', 'NN'), ('beast', 'NN'), ('continued', 'VBD'), ('voyage', 'NN'), ('met', 'VBD'), ('land', 'JJ'), ('nature', 'JJ'), ('things', 'NNS'), ('reversed', 'VBD'), ('great', 'JJ'), ('lake', 'JJ'), ('feet', 'NNS'), ('beneath', 'IN'), ('surface', 'NN'), ('water', 'NN'), ('flourished', 'VBD'), ('leaf', 'JJ'), ('forest', 'JJS'), ('tall', 'JJ'), ('luxuriant', 'NN'), ('trees', 'NNS'), ('hoo', 'VBP'), ('king', 'VBG'), ('miles', 'NNS'), ('farther', 'RB'), ('brought', 'VBD'), ('climate', 'NN'), ('atmosphere', 'NN'), ('dense', 'NN'), ('sustain', 'NN'), ('iron', 'NN'), ('steel', 'NN'), ('feather', 'RB'), ('fiddle', 'JJ'), ('dee', 'NN'), ('king', 'VBG'), ('proceeding', 'VBG'), ('direction', 'NN'), ('presently', 'RB'), ('arrived', 'VBD'), ('magnificent', 'JJ'), ('region', 'NN'), ('meandered', 'VBD'), ('glorious', 'JJ'), ('river', 'NN'), ('thousands', 'NNS'), ('miles', 'NNS'), ('river', 'RB'), ('unspeakable', 'JJ'), ('depth', 'NN'), ('transparency', 'NN'), ('richer', 'JJR'), ('amber', 'NN'), ('miles', 'NNS'), ('width', 'VBP'), ('banks', 'NNS'), ('arose', 'VBP'), ('feet', 'NNS'), ('perpendicular', 'JJ'), ('height', 'NN'), ('crowned', 'VBD'), ('blossoming', 'VBG'), ('trees', 'NNS'), ('perpetual', 'JJ'), ('sweet', 'RB'), ('scented', 'JJ'), ('flowers', 'NNS'), ('territory', 'VBP'), ('gorgeous', 'JJ'), ('garden', 'NN'), ('luxuriant', 'NN'), ('land', 'NN'), ('kingdom', 'NN'), ('horror', 'NN'), ('enter', 'RBR'), ('inevitable', 'JJ'), ('death', 'NN'), ('humph', 'NN'), ('king', 'NN'), ('left', 'VBD'), ('kingdom', 'JJ'), ('great', 'JJ'), ('haste', 'NN'), ('days', 'NNS'), ('astonished', 'VBD'), ('perceive', 'JJ'), ('myriads', 'NNS'), ('monstrous', 'JJ'), ('animals', 'NNS'), ('horns', 'NNS'), ('resembling', 'VBG'), ('scythes', 'NNS'), ('heads', 'NNS'), ('hideous', 'JJ'), ('beasts', 'NNS'), ('dig', 'VBP'), ('vast', 'JJ'), ('caverns', 'NNS'), ('soil', 'NN'), ('funnel', 'NN'), ('shape', 'NN'), ('sides', 'NNS'), ('rocks', 'NNS'), ('disposed', 'VBD'), ('fall', 'NN'), ('instantly', 'RB'), ('trodden', 'JJ'), ('animals', 'NNS'), ('precipitating', 'VBG'), ('monster', 'NN'), ('dens', 'NNS'), ('blood', 'NN'), ('sucked', 'VBD'), ('carcasses', 'NNS'), ('hurled', 'VBD'), ('contemptuously', 'RB'), ('immense', 'JJ'), ('distance', 'NN'), ('caverns', 'NNS'), ('death', 'NN'), ('pooh', 'NN'), ('king', 'VBG'), ('continuing', 'VBG'), ('progress', 'NN'), ('perceived', 'VBD'), ('district', 'NN'), ('vegetables', 'NNS'), ('grew', 'VBD'), ('soil', 'NN'), ('air', 'NN'), ('sprang', 'VBD'), ('substance', 'NN'), ('vegetables', 'NNS'), ('derived', 'VBN'), ('substance', 'NN'), ('bodies', 'NNS'), ('living', 'VBG'), ('animals', 'NNS'), ('glowed', 'VBD'), ('intense', 'JJ'), ('moved', 'VBD'), ('place', 'JJ'), ('place', 'NN'), ('pleasure', 'NN'), ('wonderful', 'NN'), ('discovered', 'VBD'), ('flowers', 'NNS'), ('lived', 'VBD'), ('breathed', 'VBN'), ('moved', 'VBN'), ('limbs', 'RBR'), ('detestable', 'JJ'), ('passion', 'NN'), ('mankind', 'IN'), ('enslaving', 'VBG'), ('creatures', 'NNS'), ('confining', 'VBG'), ('horrid', 'JJ'), ('solitary', 'JJ'), ('prisons', 'NNS'), ('fulfillment', 'NN'), ('appointed', 'VBN'), ('tasks', 'NNS'), ('pshaw', 'VBP'), ('king', 'VBG'), ('quitting', 'VBG'), ('land', 'NN'), ('arrived', 'VBD'), ('bees', 'NNS'), ('birds', 'NNS'), ('mathematicians', 'NNS'), ('genius', 'JJ'), ('erudition', 'JJ'), ('daily', 'JJ'), ('instructions', 'NNS'), ('science', 'NN'), ('geometry', 'NN'), ('wise', 'NN'), ('men', 'NNS'), ('empire', 'VBP'), ('king', 'VBG'), ('place', 'NN'), ('offered', 'VBN'), ('reward', 'JJ'), ('solution', 'NN'), ('difficult', 'JJ'), ('problems', 'NNS'), ('solved', 'VBD'), ('spot', 'NN'), ('bees', 'NNS'), ('birds', 'NNS'), ('king', 'VBG'), ('keeping', 'VBG'), ('solution', 'NN'), ('secret', 'FW'), ('profound', 'NN'), ('researches', 'NNS'), ('labor', 'NN'), ('writing', 'VBG'), ('infinity', 'NN'), ('big', 'JJ'), ('books', 'NNS'), ('long', 'JJ'), ('series', 'NN'), ('years', 'NNS'), ('men', 'NNS'), ('mathematicians', 'NNS'), ('length', 'VBP'), ('arrived', 'JJ'), ('identical', 'JJ'), ('solutions', 'NNS'), ('spot', 'VBP'), ('bees', 'NNS'), ('birds', 'NNS'), ('king', 'VBG'), ('scarcely', 'RB'), ('lost', 'VBN'), ('sight', 'NN'), ('empire', 'NN'), ('close', 'JJ'), ('shores', 'NNS'), ('flew', 'VBD'), ('heads', 'NNS'), ('flock', 'VB'), ('fowls', 'NNS'), ('mile', 'JJ'), ('breadth', 'JJ'), ('miles', 'NNS'), ('long', 'RB'), ('flew', 'VBD'), ('mile', 'IN'), ('minute', 'NN'), ('required', 'VBN'), ('hours', 'NNS'), ('flock', 'JJ'), ('pass', 'NN'), ('millions', 'NNS'), ('millions', 'NNS'), ('fowl', 'VBP'), ('king', 'VBG'), ('sooner', 'RBR'), ('rid', 'JJ'), ('birds', 'NNS'), ('occasioned', 'VBD'), ('great', 'JJ'), ('annoyance', 'NN'), ('terrified', 'VBD'), ('appearance', 'NN'), ('fowl', 'NN'), ('kind', 'NN'), ('infinitely', 'RB'), ('larger', 'JJR'), ('rocs', 'NN'), ('met', 'VBD'), ('voyages', 'NNS'), ('bigger', 'JJR'), ('biggest', 'JJS'), ('domes', 'NNS'), ('seraglio', 'JJ'), ('munificent', 'NN'), ('caliphs', 'NN'), ('terrible', 'JJ'), ('fowl', 'JJ'), ('head', 'NN'), ('perceive', 'NN'), ('fashioned', 'VBN'), ('belly', 'RB'), ('prodigious', 'JJ'), ('fatness', 'NN'), ('roundness', 'NN'), ('soft', 'JJ'), ('substance', 'NN'), ('smooth', 'JJ'), ('shining', 'VBG'), ('striped', 'JJ'), ('colors', 'NNS'), ('talons', 'NNS'), ('monster', 'VBP'), ('bearing', 'VBG'), ('eyrie', 'NN'), ('heavens', 'NNS'), ('house', 'NN'), ('knocked', 'VBD'), ('roof', 'JJ'), ('interior', 'JJ'), ('distinctly', 'RB'), ('human', 'JJ'), ('beings', 'NNS'), ('doubt', 'NN'), ('state', 'NN'), ('frightful', 'JJ'), ('despair', 'NN'), ('horrible', 'JJ'), ('fate', 'NN'), ('awaited', 'VBD'), ('shouted', 'VBN'), ('hope', 'NN'), ('frightening', 'VBG'), ('bird', 'NN'), ('letting', 'VBG'), ('prey', 'JJ'), ('snort', 'NN'), ('puff', 'NN'), ('rage', 'NN'), ('fall', 'NN'), ('heads', 'NNS'), ('heavy', 'JJ'), ('sack', 'NN'), ('proved', 'VBD'), ('filled', 'JJ'), ('sand', 'NN'), ('stuff', 'NN'), ('king', 'VBG'), ('adventure', 'NN'), ('encountered', 'VBD'), ('continent', 'JJ'), ('immense', 'JJ'), ('extent', 'NN'), ('prodigious', 'JJ'), ('solidity', 'NN'), ('supported', 'VBD'), ('sky', 'JJ'), ('blue', 'JJ'), ('cow', 'NN'), ('fewer', 'JJR'), ('horns', 'NNS'), ('king', 'VBG'), ('read', 'JJ'), ('kind', 'NN'), ('book', 'NN'), ('passed', 'VBD'), ('beneath', 'JJ'), ('continent', 'NN'), ('swimming', 'VBG'), ('legs', 'JJ'), ('cow', 'NN'), ('hours', 'NNS'), ('wonderful', 'JJ'), ('country', 'NN'), ('informed', 'VBD'), ('man', 'NN'), ('animal', 'NN'), ('native', 'JJ'), ('land', 'NN'), ('inhabited', 'VBN'), ('things', 'NNS'), ('species', 'NNS'), ('elevated', 'VBD'), ('man', 'NN'), ('animal', 'NN'), ('esteem', 'VBP'), ('fact', 'NN'), ('began', 'VBD'), ('feel', 'RB'), ('ashamed', 'VBN'), ('contemptuous', 'JJ'), ('familiarity', 'NN'), ('treated', 'VBN'), ('man', 'NN'), ('animals', 'VBZ'), ('general', 'JJ'), ('nation', 'NN'), ('powerful', 'JJ'), ('magicians', 'NNS'), ('lived', 'VBD'), ('worms', 'NNS'), ('brain', 'NN'), ('doubt', 'NN'), ('served', 'VBD'), ('stimulate', 'JJ'), ('painful', 'JJ'), ('writhings', 'NNS'), ('wrigglings', 'NNS'), ('miraculous', 'JJ'), ('efforts', 'NNS'), ('imagination', 'NN'), ('nonsense', 'IN'), ('king', 'VBG'), ('magicians', 'NNS'), ('domesticated', 'VBN'), ('animals', 'NNS'), ('singular', 'JJ'), ('kinds', 'NNS'), ('huge', 'JJ'), ('horse', 'NN'), ('bones', 'NNS'), ('iron', 'RB'), ('blood', 'VBD'), ('boiling', 'JJ'), ('water', 'NN'), ('place', 'NN'), ('corn', 'NN'), ('black', 'JJ'), ('stones', 'NNS'), ('usual', 'JJ'), ('food', 'NN'), ('spite', 'RB'), ('hard', 'JJ'), ('diet', 'NN'), ('strong', 'JJ'), ('swift', 'NN'), ('drag', 'NN'), ('load', 'NN'), ('weighty', 'NN'), ('grandest', 'JJS'), ('temple', 'JJ'), ('city', 'NN'), ('rate', 'NN'), ('surpassing', 'VBG'), ('flight', 'NN'), ('birds', 'NNS'), ('twattle', 'JJ'), ('king', 'VBG'), ('people', 'NNS'), ('hen', 'VBP'), ('feathers', 'NNS'), ('bigger', 'JJR'), ('camel', 'NN'), ('flesh', 'JJ'), ('bone', 'NN'), ('iron', 'NN'), ('brick', 'NN'), ('blood', 'NN'), ('horse', 'NN'), ('fact', 'NN'), ('boiling', 'VBG'), ('water', 'NN'), ('ate', 'NN'), ('wood', 'NN'), ('black', 'JJ'), ('stones', 'NNS'), ('hen', 'NN'), ('brought', 'VBD'), ('frequently', 'RB'), ('chickens', 'VBZ'), ('day', 'NN'), ('birth', 'JJ'), ('residence', 'NN'), ('weeks', 'NNS'), ('stomach', 'VBP'), ('mother', 'RB'), ('fal', 'JJ'), ('lal', 'NN'), ('king', 'VBG'), ('nation', 'NN'), ('mighty', 'NN'), ('conjurors', 'NNS'), ('created', 'VBD'), ('man', 'NN'), ('brass', 'NN'), ('wood', 'NN'), ('leather', 'NN'), ('endowed', 'VBN'), ('ingenuity', 'NN'), ('beaten', 'NN'), ('chess', 'NN'), ('race', 'NN'), ('mankind', 'NN'), ('exception', 'NN'), ('great', 'JJ'), ('caliph', 'NN'), ('haroun', 'NN'), ('alraschid', 'NN'), ('magi', 'NN'), ('constructed', 'VBN'), ('material', 'JJ'), ('creature', 'NN'), ('shame', 'NN'), ('genius', 'NN'), ('great', 'JJ'), ('reasoning', 'VBG'), ('powers', 'NNS'), ('performed', 'VBD'), ('calculations', 'NNS'), ('vast', 'JJ'), ('extent', 'NN'), ('required', 'VBN'), ('united', 'JJ'), ('labor', 'NN'), ('fifty', 'JJ'), ('fleshy', 'JJ'), ('men', 'NNS'), ('year', 'NN'), ('wonderful', 'JJ'), ('conjuror', 'NN'), ('fashioned', 'VBD'), ('mighty', 'JJ'), ('thing', 'NN'), ('man', 'NN'), ('beast', 'NN'), ('brains', 'VBZ'), ('lead', 'JJ'), ('intermixed', 'JJ'), ('black', 'JJ'), ('matter', 'NN'), ('pitch', 'NN'), ('fingers', 'NNS'), ('employed', 'VBD'), ('incredible', 'JJ'), ('speed', 'NN'), ('dexterity', 'NN'), ('trouble', 'NN'), ('writing', 'VBG'), ('copies', 'NNS'), ('koran', 'VBD'), ('hour', 'NN'), ('exquisite', 'JJ'), ('precision', 'NN'), ('copies', 'NNS'), ('vary', 'VBP'), ('breadth', 'JJ'), ('finest', 'JJS'), ('hair', 'NN'), ('thing', 'NN'), ('prodigious', 'JJ'), ('strength', 'NN'), ('erected', 'VBD'), ('overthrew', 'JJ'), ('mightiest', 'JJS'), ('empires', 'NNS'), ('breath', 'VBP'), ('powers', 'NNS'), ('exercised', 'VBN'), ('equally', 'RB'), ('evil', 'JJ'), ('good', 'JJ'), ('ridiculous', 'JJ'), ('king', 'VBG'), ('nation', 'NN'), ('necromancers', 'NNS'), ('veins', 'VBZ'), ('blood', 'NN'), ('salamanders', 'NNS'), ('scruple', 'VBD'), ('sitting', 'VBG'), ('smoke', 'NN'), ('chibouc', 'NNS'), ('red', 'VBD'), ('hot', 'JJ'), ('oven', 'RB'), ('dinner', 'NN'), ('roasted', 'VBD'), ('floor', 'NN'), ('faculty', 'NN'), ('converting', 'VBG'), ('common', 'JJ'), ('metals', 'NNS'), ('gold', 'JJ'), ('process', 'NN'), ('delicacy', 'NN'), ('touch', 'JJ'), ('wire', 'NN'), ('fine', 'NN'), ('invisible', 'JJ'), ('quickness', 'JJ'), ('perception', 'NN'), ('counted', 'VBN'), ('separate', 'JJ'), ('motions', 'NNS'), ('elastic', 'JJ'), ('body', 'NN'), ('springing', 'VBG'), ('backward', 'JJ'), ('forward', 'NN'), ('rate', 'NN'), ('millions', 'NNS'), ('times', 'NNS'), ('absurd', 'JJ'), ('king', 'NN'), ('magicians', 'NNS'), ('fluid', 'VBP'), ('corpses', 'NNS'), ('friends', 'NNS'), ('brandish', 'JJ'), ('arms', 'NNS'), ('kick', 'VBP'), ('legs', 'JJ'), ('fight', 'NN'), ('dance', 'NN'), ('cultivated', 'VBD'), ('voice', 'NN'), ('great', 'JJ'), ('extent', 'JJ'), ('heard', 'NN'), ('long', 'RB'), ('arm', 'JJ'), ('sit', 'NN'), ('damascus', 'NN'), ('indite', 'JJ'), ('letter', 'NN'), ('bagdad', 'NN'), ('distance', 'NN'), ('whatsoever', 'RB'), ('commanded', 'VBD'), ('lightning', 'VBG'), ('heavens', 'NNS'), ('served', 'VBD'), ('plaything', 'VBG'), ('loud', 'JJ'), ('sounds', 'NNS'), ('silence', 'RB'), ('constructed', 'VBD'), ('deep', 'JJ'), ('darkness', 'NN'), ('brilliant', 'JJ'), ('lights', 'NNS'), ('ice', 'NN'), ('red', 'VBD'), ('hot', 'JJ'), ('furnace', 'NN'), ('directed', 'VBD'), ('sun', 'JJ'), ('paint', 'NN'), ('portrait', 'NN'), ('sun', 'NN'), ('luminary', 'JJ'), ('moon', 'NN'), ('planets', 'NNS'), ('weighed', 'VBD'), ('scrupulous', 'JJ'), ('accuracy', 'NN'), ('probed', 'VBD'), ('depths', 'JJ'), ('solidity', 'NN'), ('substance', 'NN'), ('nation', 'NN'), ('surprising', 'JJ'), ('necromantic', 'JJ'), ('ability', 'NN'), ('infants', 'NNS'), ('commonest', 'VBP'), ('cats', 'NNS'), ('dogs', 'NNS'), ('difficulty', 'NN'), ('objects', 'NNS'), ('exist', 'VBP'), ('millions', 'NNS'), ('years', 'NNS'), ('birth', 'JJ'), ('nation', 'NN'), ('blotted', 'VBD'), ('face', 'NN'), ('creation', 'NN'), ('preposterous', 'JJ'), ('king', 'VBG'), ('wives', 'NNS'), ('daughters', 'NNS'), ('incomparably', 'RB'), ('great', 'JJ'), ('wise', 'NN'), ('magi', 'NN'), ('continued', 'VBD'), ('scheherazade', 'JJ'), ('manner', 'NN'), ('disturbed', 'VBD'), ('frequent', 'JJ'), ('ungentlemanly', 'JJ'), ('interruptions', 'NNS'), ('husband', 'VBP'), ('wives', 'VBZ'), ('daughters', 'NNS'), ('eminent', 'JJ'), ('conjurers', 'NNS'), ('thing', 'NN'), ('accomplished', 'VBD'), ('refined', 'JJ'), ('thing', 'NN'), ('interesting', 'VBG'), ('beautiful', 'JJ'), ('unhappy', 'JJ'), ('fatality', 'NN'), ('besets', 'NNS'), ('miraculous', 'JJ'), ('powers', 'NNS'), ('husbands', 'VBZ'), ('fathers', 'NNS'), ('hitherto', 'JJ'), ('adequate', 'JJ'), ('save', 'NN'), ('fatalities', 'NNS'), ('shapes', 'VBZ'), ('speak', 'JJ'), ('shape', 'NN'), ('crotchet', 'NN'), ('king', 'VBG'), ('crotchet', 'NN'), ('scheherazade', 'VBD'), ('evil', 'JJ'), ('genii', 'NN'), ('perpetually', 'RB'), ('watch', 'VB'), ('inflict', 'NN'), ('ill', 'NN'), ('heads', 'NNS'), ('accomplished', 'VBD'), ('ladies', 'NNS'), ('thing', 'NN'), ('personal', 'JJ'), ('beauty', 'NN'), ('consists', 'VBZ'), ('altogether', 'RB'), ('protuberance', 'JJ'), ('region', 'NN'), ('lies', 'VBZ'), ('small', 'JJ'), ('perfection', 'NN'), ('loveliness', 'NN'), ('direct', 'JJ'), ('ratio', 'NN'), ('extent', 'NN'), ('lump', 'NN'), ('long', 'RB'), ('possessed', 'VBD'), ('idea', 'NN'), ('bolsters', 'NNS'), ('cheap', 'JJ'), ('country', 'NN'), ('days', 'NNS'), ('long', 'RB'), ('distinguish', 'JJ'), ('woman', 'NN'), ('dromedary', 'JJ'), ('king', 'NN'), ('stand', 'NN'), ('dreadful', 'JJ'), ('headache', 'NN'), ('lies', 'VBZ'), ('day', 'NN'), ('perceive', 'JJ'), ('break', 'NN'), ('long', 'JJ'), ('married', 'JJ'), ('conscience', 'NN'), ('troublesome', 'JJ'), ('dromedary', 'JJ'), ('touch', 'NN'), ('fool', 'NN'), ('throttled', 'VBD'), ('learn', 'JJ'), ('isits', 'NNS'), ('ornot', 'VBP'), ('grieved', 'VBN'), ('astonished', 'JJ'), ('scheherazade', 'NN'), ('knew', 'VBD'), ('king', 'VBG'), ('man', 'NN'), ('scrupulous', 'JJ'), ('integrity', 'NN'), ('forfeit', 'NN'), ('word', 'NN'), ('submitted', 'VBN'), ('fate', 'RB'), ('good', 'JJ'), ('grace', 'NN'), ('derived', 'VBD'), ('great', 'JJ'), ('consolation', 'NN'), ('tightening', 'VBG'), ('bowstring', 'VBG'), ('reflection', 'NN'), ('history', 'NN'), ('remained', 'VBD'), ('untold', 'JJ'), ('petulance', 'NN'), ('brute', 'NN'), ('husband', 'NN'), ('reaped', 'VBD'), ('righteous', 'JJ'), ('reward', 'NN'), ('depriving', 'VBG'), ('inconceivable', 'JJ'), ('adventures', 'NNS')]]\n"
     ]
    }
   ],
   "source": [
    "print(all_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a8349",
   "metadata": {},
   "source": [
    "### q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ce66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun, common, singular or mass\n",
      "dict_keys(['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/nanxiliu/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.data import load\n",
    "nltk.download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "print(tagdict['NN'][0])\n",
    "print(tagdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f867c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NN': ['truth', 'stranger', 'fiction', 'occasion', 'work', 'zohar', 'simeon', 'knowledge', 'author', 'literature', 'occasion', 'turn', 'work', 'hitherto', 'fate', 'vizier', 'daughter', 'scheherazade', 'fate', 'blame', 'topic', 'reader', 'version', 'queen', 'death', 'vow', 'beard', 'prophet', 'espouse', 'night', 'morning', 'deliver', 'executioner', 'letter', 'punctuality', 'method', 'credit', 'man', 'sense', 'afternoon', 'doubt', 'vizier', 'daughter', 'idea', 'scheherazade', 'idea', 'land', 'tax', 'beauty', 'perish', 'fashion', 'attempt', 'year', 'vizier', 'offer', 'hand', 'hand', 'day', 'day', 'design', 'iota', 'vow', 'king', 'marry', 'advice', 'thing', 'kind', 'marry', 'nature', 'case', 'damsel', 'doubt', 'plot', 'mind', 'night', 'pretence', 'sister', 'royal', 'pair', 'conversation', 'cock', 'care', 'monarch', 'husband', 'neck', 'morrow', 'account', 'capital', 'conscience', 'digestion', 'story', 'rat', 'cat', 'sister', 'day', 'history', 'nature', 'time', 'thing', 'genteel', 'curiosity', 'vow', 'morning', 'hope', 'night', 'cat', 'cat', 'rat', 'night', 'scheherazade', 'cat', 'rat', 'rat', 'reference', 'horse', 'manner', 'clockwork', 'wound', 'indigo', 'history', 'day', 'conclusion', 'time', 'resource', 'postpone', 'ceremony', 'night', 'result', 'monarch', 'opportunity', 'vow', 'period', 'time', 'father', 'confessor', 'eve', 'tariff', 'beauty', 'conclusion', 'story', 'record', 'doubt', 'error', 'mieux', 'proverb', 'ennemi', 'bien', 'scheherazade', 'compound', 'sister', 'night', 'quote', 'language', 'point', 'verbatim', 'sister', 'difficulty', 'tax', 'indiscretion', 'thing', 'conclusion', 'sinbad', 'sailor', 'person', 'night', 'narration', 'piece', 'misconduct', 'trust', 'remedy', 'king', 'pinch', 'order', 'wake', 'noise', 'forthwith', 'entertain', 'story', 'sister', 'intensity', 'gratification', 'length', 'hoo', 'queen', 'doubt', 'signify', 'attention', 'snore', 'satisfaction', 'history', 'sinbad', 'sailor', 'length', 'age', 'sinbad', 'length', 'age', 'tranquillity', 'desire', 'day', 'family', 'design', 'merchandise', 'bulky', 'porter', 'sea', 'shore', 'await', 'chance', 'vessel', 'convey', 'kingdom', 'region', 'beneath', 'hope', 'porter', 'distinguish', 'louder', 'doubt', 'object', 'length', 'edge', 'horizon', 'speck', 'size', 'vast', 'monster', 'body', 'surface', 'sea', 'swiftness', 'sea', 'distance', 'thing', 'audience', 'palace', 'munificent', 'caliphs', 'body', 'rock', 'jetty', 'blackness', 'portion', 'water', 'exception', 'blood', 'streak', 'beneath', 'surface', 'glimpse', 'monster', 'color', 'moon', 'misty', 'weather', 'half', 'length', 'body', 'creature', 'mouth', 'deficiency', 'dragon', 'fly', 'body', 'blood', 'streak', 'answer', 'purpose', 'eyebrow', 'appearance', 'gold', 'beast', 'rapidity', 'necromancy', 'manner', 'forward', 'tail', 'monster', 'breath', 'violence', 'noise', 'terror', 'thing', 'astonishment', 'nearer', 'creature', 'number', 'size', 'shape', 'doubt', 'deal', 'cloth', 'skin', 'render', 'pain', 'answer', 'weight', 'direction', 'body', 'time', 'contemplation', 'snubby', 'wonderful', 'degree', 'monster', 'extent', 'flash', 'cloud', 'thunder', 'smoke', 'man', 'head', 'beast', 'trumpet', 'hand', 'mouth', 'harsh', 'language', 'loss', 'reply', 'manner', 'difficulty', 'opinion', 'kind', 'trepidation', 'heard', 'sea', 'beast', 'cruel', 'demon', 'blood', 'genii', 'misery', 'mankind', 'savage', 'vermin', 'torture', 'wrath', 'requisite', 'roar', 'commit', 'ill', 'account', 'speed', 'direction', 'care', 'point', 'determine', 'shore', 'hand', 'foot', 'beast', 'swam', 'sea', 'life', 'condition', 'secure', 'goodwill', 'man', 'animal', 'trumpet', 'authority', 'endeavor', 'creature', 'favor', 'trouble', 'language', 'length', 'comprehend', 'ardent', 'desire', 'squeak', 'sinbad', 'hey', 'grunt', 'unt', 'day', 'dinner', 'beg', 'conversant', 'dialect', 'cock', 'man', 'language', 'link', 'horse', 'rooster', 'permission', 'translate', 'dear', 'sinbad', 'thing', 'globe', 'strain', 'point', 'passage', 'beast', 'lady', 'scheherazade', 'fact', 'dear', 'hitherto', 'king', 'scheherazade', 'history', 'sinbad', 'manner', 'man', 'animal', 'kindness', 'beast', 'rate', 'surface', 'round', 'pomegranate', 'hill', 'time', 'scheherazade', 'pray', 'story', 'beast', 'caliph', 'swam', 'hill', 'length', 'island', 'sea', 'colony', 'island', 'sinbad', 'husband', 'ill', 'ejaculation', 'island', 'hum', 'scheherazade', 'attention', 'language', 'sinbad', 'island', 'country', 'distance', 'thirty', 'earth', 'number', 'roofs', 'ebony', 'swam', 'region', 'sea', 'lofty', 'mountain', 'summit', 'quantity', 'darker', 'midnight', 'distance', 'object', 'hum', 'coast', 'beast', 'voyage', 'surface', 'water', 'luxuriant', 'climate', 'atmosphere', 'dense', 'sustain', 'iron', 'steel', 'dee', 'direction', 'region', 'river', 'depth', 'transparency', 'amber', 'height', 'garden', 'luxuriant', 'land', 'kingdom', 'horror', 'death', 'humph', 'king', 'haste', 'soil', 'funnel', 'shape', 'fall', 'monster', 'blood', 'distance', 'death', 'pooh', 'progress', 'district', 'soil', 'air', 'substance', 'substance', 'place', 'pleasure', 'wonderful', 'passion', 'fulfillment', 'land', 'science', 'geometry', 'wise', 'place', 'solution', 'spot', 'solution', 'profound', 'labor', 'infinity', 'series', 'sight', 'empire', 'minute', 'pass', 'annoyance', 'appearance', 'fowl', 'kind', 'rocs', 'munificent', 'caliphs', 'head', 'perceive', 'fatness', 'roundness', 'substance', 'eyrie', 'house', 'doubt', 'state', 'despair', 'fate', 'hope', 'bird', 'snort', 'puff', 'rage', 'fall', 'sack', 'sand', 'stuff', 'adventure', 'extent', 'solidity', 'cow', 'kind', 'book', 'continent', 'cow', 'country', 'man', 'animal', 'land', 'man', 'animal', 'fact', 'familiarity', 'man', 'nation', 'brain', 'doubt', 'imagination', 'horse', 'water', 'place', 'corn', 'food', 'diet', 'swift', 'drag', 'load', 'weighty', 'city', 'rate', 'flight', 'camel', 'bone', 'iron', 'brick', 'blood', 'horse', 'fact', 'water', 'ate', 'wood', 'hen', 'day', 'residence', 'lal', 'nation', 'mighty', 'man', 'brass', 'wood', 'leather', 'ingenuity', 'beaten', 'chess', 'race', 'mankind', 'exception', 'caliph', 'haroun', 'alraschid', 'magi', 'creature', 'shame', 'genius', 'extent', 'labor', 'year', 'conjuror', 'thing', 'man', 'beast', 'matter', 'pitch', 'speed', 'dexterity', 'trouble', 'hour', 'precision', 'hair', 'thing', 'strength', 'nation', 'blood', 'smoke', 'dinner', 'floor', 'faculty', 'process', 'delicacy', 'wire', 'fine', 'perception', 'body', 'forward', 'rate', 'king', 'fight', 'dance', 'voice', 'heard', 'sit', 'damascus', 'letter', 'bagdad', 'distance', 'darkness', 'ice', 'furnace', 'paint', 'portrait', 'sun', 'moon', 'accuracy', 'solidity', 'substance', 'nation', 'ability', 'difficulty', 'nation', 'face', 'creation', 'wise', 'magi', 'manner', 'thing', 'thing', 'fatality', 'save', 'shape', 'crotchet', 'crotchet', 'genii', 'inflict', 'ill', 'thing', 'beauty', 'region', 'perfection', 'loveliness', 'ratio', 'extent', 'lump', 'idea', 'country', 'woman', 'king', 'stand', 'headache', 'day', 'break', 'conscience', 'touch', 'fool', 'scheherazade', 'man', 'integrity', 'forfeit', 'word', 'grace', 'consolation', 'reflection', 'history', 'petulance', 'brute', 'husband', 'reward'], 'JJ': ['oriental', 'tellmenow', 'american', 'american', 'remarkable', 'literary', 'error', 'arabian', 'nouement', 'inaccurate', 'interesting', 'inquisitive', 'summary', 'remembered', 'usual', 'good', 'jealous', 'beautiful', 'maiden', 'religious', 'great', 'excellent', 'grand', 'leap', 'meritorious', 'grand', 'matter', 'grand', 'grand', 'insisted', 'excellent', 'beautiful', 'black', 'open', 'politic', 'machiavelli', 'ingenious', 'specious', 'couch', 'easy', 'bed', 'good', 'awaken', 'easy', 'profound', 'black', 'undertone', 'scheherazade', 'finish', 'high', 'bowstrung', 'pleasant', 'trifle', 'sound', 'religious', 'postpone', 'fulfilment', 'purpose', 'black', 'black', 'lady', 'black', 'blue', 'deep', 'mistaken', 'pink', 'green', 'violent', 'key', 'interested', 'queen', 'accident', 'good', 'expiration', 'regular', 'probable', 'lady', 'proper', 'pleasant', 'great', 'pleasant', 'true', 'indebted', 'french', 'seventy', 'dear', 'ornot', 'odious', 'guilty', 'great', 'gentleman', 'numerous', 'interesting', 'sleepy', 'grievous', 'forgive', 'late', 'great', 'neglect', 'horrible', 'remarkable', 'pinched', 'hum', 'arabic', 'queen', 'scheherazade', 'foreign', 'precious', 'arrival', 'ocean', 'ship', 'hear', 'singular', 'sound', 'black', 'great', 'inconceivable', 'huge', 'length', 'equal', 'wide', 'great', 'hall', 'sublime', 'ordinary', 'solid', 'narrow', 'red', 'metallic', 'flat', 'white', 'horrible', 'perceive', 'green', 'red', 'dreadful', 'solid', 'fish', 'web', 'duck', 'blown', 'writhe', 'small', 'thick', 'prodigious', 'disagreeable', 'hideous', 'great', 'surpassed', 'vast', 'nature', 'uncomfortable', 'good', 'tight', 'poor', 'severe', 'heavy', 'great', 'steady', 'safe', 'black', 'doubt', 'impossible', 'poor', 'perpetual', 'puggish', 'awful', 'stood', 'pushed', 'great', 'terrible', 'dense', 'compare', 'odd', 'large', 'loud', 'disagreeable', 'mistaken', 'spoken', 'evil', 'evil', 'beast', 'nibbling', 'degree', 'vengeful', 'malicious', 'genii', 'fast', 'opposite', 'escape', 'excellent', 'swarm', 'bound', 'middle', 'comfortable', 'peril', 'useless', 'exercise', 'denominate', 'converse', 'washish', 'squashish', 'diddle', 'grumble', 'hiss', 'fiss', 'whiss', 'majesty', 'presume', 'washish', 'squashish', 'happy', 'excellent', 'fellow', 'desirous', 'free', 'turned', 'left', 'surprising', 'queen', 'entertaining', 'strange', 'fair', 'narrative', 'swam', 'prodigious', 'ocean', 'flat', 'hill', 'singular', 'true', 'good', 'queen', 'sinbad', 'middle', 'understood', 'notice', 'hard', 'cut', 'spacious', 'magnificent', 'bagdad', 'immense', 'black', 'fish', 'metal', 'wide', 'abyss', 'vast', 'fifty', 'impossible', 'close', 'land', 'nature', 'great', 'lake', 'leaf', 'tall', 'fiddle', 'magnificent', 'glorious', 'unspeakable', 'perpendicular', 'perpetual', 'scented', 'gorgeous', 'inevitable', 'kingdom', 'great', 'perceive', 'monstrous', 'hideous', 'vast', 'trodden', 'immense', 'intense', 'place', 'detestable', 'horrid', 'solitary', 'genius', 'erudition', 'daily', 'reward', 'difficult', 'big', 'long', 'arrived', 'identical', 'close', 'mile', 'breadth', 'flock', 'rid', 'great', 'seraglio', 'terrible', 'fowl', 'prodigious', 'soft', 'smooth', 'striped', 'roof', 'interior', 'human', 'frightful', 'horrible', 'prey', 'heavy', 'filled', 'continent', 'immense', 'prodigious', 'sky', 'blue', 'read', 'beneath', 'legs', 'wonderful', 'native', 'contemptuous', 'general', 'powerful', 'stimulate', 'painful', 'miraculous', 'singular', 'huge', 'boiling', 'black', 'usual', 'hard', 'strong', 'temple', 'twattle', 'flesh', 'black', 'birth', 'fal', 'great', 'material', 'great', 'vast', 'united', 'fifty', 'fleshy', 'wonderful', 'mighty', 'lead', 'intermixed', 'black', 'incredible', 'exquisite', 'breadth', 'prodigious', 'overthrew', 'evil', 'good', 'ridiculous', 'hot', 'common', 'gold', 'touch', 'invisible', 'quickness', 'separate', 'elastic', 'backward', 'absurd', 'brandish', 'legs', 'great', 'extent', 'arm', 'indite', 'loud', 'deep', 'brilliant', 'hot', 'sun', 'luminary', 'scrupulous', 'depths', 'surprising', 'necromantic', 'birth', 'preposterous', 'great', 'scheherazade', 'frequent', 'ungentlemanly', 'eminent', 'refined', 'beautiful', 'unhappy', 'miraculous', 'hitherto', 'adequate', 'speak', 'evil', 'personal', 'protuberance', 'small', 'direct', 'cheap', 'distinguish', 'dromedary', 'dreadful', 'perceive', 'long', 'married', 'troublesome', 'dromedary', 'learn', 'astonished', 'scrupulous', 'good', 'great', 'untold', 'righteous', 'inconceivable'], 'NNS': ['investigations', 'isits', 'jochaides', 'curiosities', 'nights', 'isits', 'tales', 'dominions', 'years', 'prayers', 'heroines', 'deputes', 'accepts', 'events', 'parties', 'privileges', 'eyes', 'things', 'principles', 'intricacies', 'wings', 'endeavors', 'hours', 'nights', 'breaks', 'events', 'baskets', 'trees', 'alas', 'things', 'baskets', 'snores', 'adventures', 'pleases', 'isits', 'ornot', 'matters', 'years', 'countries', 'bundles', 'packages', 'sands', 'trees', 'hours', 'waves', 'trees', 'fishes', 'billows', 'scales', 'upwards', 'spines', 'eyes', 'sockets', 'rows', 'eyes', 'fins', 'feet', 'wings', 'eels', 'holes', 'nostrils', 'animals', 'men', 'garments', 'men', 'wretches', 'tips', 'heads', 'boxes', 'turbans', 'solid', 'contrivances', 'heads', 'animals', 'shoulders', 'necks', 'creatures', 'collars', 'badges', 'dogs', 'victims', 'heads', 'noses', 'eyes', 'animals', 'accents', 'species', 'creatures', 'bowels', 'things', 'cats', 'dogs', 'stingings', 'designs', 'heels', 'hills', 'bundles', 'men', 'boats', 'adventures', 'fellows', 'days', 'tokens', 'rudiments', 'pardons', 'neighs', 'animals', 'isits', 'adventures', 'doubts', 'hundreds', 'miles', 'things', 'caterpillars', 'forests', 'pieces', 'axes', 'miles', 'bowels', 'palaces', 'palaces', 'myriads', 'diamonds', 'men', 'towers', 'pyramids', 'temples', 'rivers', 'eyes', 'sides', 'torrents', 'miles', 'miles', 'ashes', 'heavens', 'miles', 'eyes', 'things', 'feet', 'trees', 'miles', 'thousands', 'miles', 'miles', 'banks', 'feet', 'trees', 'flowers', 'days', 'myriads', 'animals', 'horns', 'scythes', 'heads', 'beasts', 'caverns', 'sides', 'rocks', 'animals', 'dens', 'carcasses', 'caverns', 'vegetables', 'vegetables', 'bodies', 'animals', 'flowers', 'creatures', 'prisons', 'tasks', 'bees', 'birds', 'mathematicians', 'instructions', 'men', 'problems', 'bees', 'birds', 'researches', 'books', 'years', 'men', 'mathematicians', 'solutions', 'bees', 'birds', 'shores', 'heads', 'fowls', 'miles', 'hours', 'millions', 'millions', 'birds', 'voyages', 'domes', 'colors', 'talons', 'heavens', 'beings', 'heads', 'horns', 'hours', 'things', 'species', 'magicians', 'worms', 'writhings', 'wrigglings', 'efforts', 'magicians', 'animals', 'kinds', 'bones', 'stones', 'birds', 'people', 'feathers', 'stones', 'weeks', 'conjurors', 'powers', 'calculations', 'men', 'fingers', 'copies', 'copies', 'empires', 'powers', 'necromancers', 'salamanders', 'chibouc', 'metals', 'motions', 'millions', 'times', 'magicians', 'corpses', 'friends', 'arms', 'heavens', 'sounds', 'lights', 'planets', 'infants', 'cats', 'dogs', 'objects', 'millions', 'years', 'wives', 'daughters', 'interruptions', 'daughters', 'conjurers', 'besets', 'powers', 'fathers', 'fatalities', 'heads', 'ladies', 'bolsters', 'days', 'isits', 'adventures'], 'VBP': ['consult', 'ornot', 'europe', 'refer', 'ornot', 'monarch', 'visit', 'redeem', 'understand', 'fair', 'occupy', 'admit', 'narration', 'talk', 'garden', 'pleasant', 'talk', 'dear', 'truth', 'sequel', 'carry', 'length', 'foam', 'grow', 'parallel', 'seashell', 'head', 'puffed', 'square', 'servitude', 'stiffer', 'view', 'understand', 'sulphur', 'vermin', 'porter', 'doubt', 'vermin', 'overtaken', 'regret', 'vain', 'diddle', 'forgotten', 'sinbad', 'hum', 'solid', 'damascus', 'hum', 'hoo', 'width', 'arose', 'territory', 'dig', 'pshaw', 'empire', 'length', 'spot', 'fowl', 'monster', 'esteem', 'hen', 'stomach', 'vary', 'breath', 'fluid', 'kick', 'commonest', 'exist', 'husband', 'ornot'], 'RB': ['scarcely', 'discover', 'strangely', 'altogether', 'sacrifice', 'father', 'eagerly', 'distinctly', 'scheherazade', 'nill', 'forget', 'awaken', 'altogether', 'altogether', 'profoundly', 'unavoidably', 'altogether', 'lineally', 'eden', 'finally', 'excessively', 'altogether', 'blown', 'happily', 'short', 'allah', 'finally', 'awhile', 'presently', 'rapidly', 'long', 'distinctly', 'completely', 'belly', 'score', 'altogether', 'precisely', 'altogether', 'ugly', 'laughably', 'awkward', 'thought', 'excessively', 'infinitely', 'positively', 'shore', 'suddenly', 'noise', 'presently', 'altogether', 'nose', 'evidently', 'porter', 'affright', 'porter', 'equally', 'finally', 'hotly', 'bitterly', 'folly', 'exceedingly', 'circumference', 'stone', 'long', 'sun', 'mountain', 'farther', 'feather', 'presently', 'river', 'sweet', 'instantly', 'contemptuously', 'scarcely', 'long', 'infinitely', 'belly', 'distinctly', 'feel', 'iron', 'spite', 'frequently', 'mother', 'equally', 'oven', 'long', 'whatsoever', 'silence', 'incomparably', 'perpetually', 'altogether', 'long', 'long', 'fate'], 'VBN': ['quoted', 'pardoned', 'intended', 'descended', 'picked', 'scheherazade', 'triumphed', 'inherited', 'deposited', 'fancied', 'declared', 'extended', 'floated', 'covered', 'extended', 'shaped', 'intended', 'designed', 'doomed', 'demanded', 'replied', 'created', 'beheld', 'pursued', 'repented', 'called', 'expressed', 'replied', 'arrived', 'mannered', 'tempered', 'contained', 'melted', 'derived', 'breathed', 'moved', 'appointed', 'offered', 'lost', 'required', 'fashioned', 'shouted', 'inhabited', 'ashamed', 'treated', 'domesticated', 'endowed', 'constructed', 'required', 'exercised', 'counted', 'grieved', 'submitted'], 'VBD': ['mentioned', 'astonished', 'depicted', 'discovered', 'fulfilled', 'conferred', 'interrupted', 'occurred', 'approved', 'intended', 'contrived', 'bed', 'bore', 'managed', 'slept', 'broke', 'happened', 'finished', 'induced', 'fared', 'arrived', 'stroke', 'knew', 'broke', 'happened', 'deprived', 'absolved', 'scheherazade', 'fell', 'repealed', 'amounted', 'repealed', 'felt', 'seduced', 'scheherazade', 'expressed', 'ceased', 'arranged', 'entered', 'retailed', 'possessed', 'packed', 'explored', 'sat', 'looked', 'grew', 'caused', 'discovered', 'increased', 'passed', 'drew', 'floated', 'begirdled', 'rose', 'fell', 'provided', 'protruded', 'arranged', 'approached', 'moved', 'served', 'perceived', 'supplied', 'sight', 'discovered', 'concluded', 'fastened', 'reached', 'emitted', 'accompanied', 'smoke', 'cleared', 'addressed', 'turned', 'wanted', 'swarmed', 'caused', 'goaded', 'wicked', 'determined', 'conveyed', 'exerted', 'owned', 'appeared', 'succeeded', 'bestowed', 'enabled', 'called', 'formed', 'proceeded', 'told', 'resumed', 'thanked', 'interrupted', 'rejoined', 'continued', 'built', 'scheherazade', 'shivered', 'endeavoured', 'continued', 'reached', 'hung', 'flowed', 'streamed', 'issued', 'blotted', 'held', 'continued', 'met', 'reversed', 'flourished', 'brought', 'arrived', 'meandered', 'crowned', 'left', 'astonished', 'disposed', 'sucked', 'hurled', 'perceived', 'grew', 'sprang', 'glowed', 'moved', 'discovered', 'lived', 'arrived', 'solved', 'flew', 'flew', 'occasioned', 'terrified', 'met', 'knocked', 'awaited', 'proved', 'encountered', 'supported', 'passed', 'informed', 'elevated', 'began', 'lived', 'served', 'blood', 'brought', 'created', 'performed', 'fashioned', 'employed', 'koran', 'erected', 'scruple', 'red', 'roasted', 'cultivated', 'commanded', 'served', 'constructed', 'red', 'directed', 'weighed', 'probed', 'blotted', 'continued', 'disturbed', 'accomplished', 'scheherazade', 'accomplished', 'possessed', 'throttled', 'knew', 'derived', 'remained', 'reaped'], 'VBG': ['respecting', 'feeling', 'depopulating', 'king', 'king', 'accepting', 'marrying', 'reading', 'wedding', 'crowing', 'wring', 'narrating', 'hanging', 'king', 'prevailing', 'hearing', 'finishing', 'king', 'notwithstanding', 'bowstringing', 'correcting', 'mentioning', 'bowstring', 'withholding', 'king', 'cutting', 'making', 'king', 'snoring', 'understanding', 'enjoying', 'visiting', 'acquainting', 'engaging', 'perceiving', 'buzzing', 'humming', 'listening', 'approaching', 'swimming', 'throwing', 'illuminating', 'shrieking', 'beholding', 'resembling', 'covering', 'fitting', 'moving', 'standing', 'putting', 'swooning', 'inflicting', 'quitting', 'teaching', 'connecting', 'circumnavigating', 'king', 'king', 'king', 'king', 'leaving', 'leaving', 'king', 'paying', 'passing', 'swarming', 'king', 'king', 'quitting', 'king', 'king', 'proceeding', 'blossoming', 'resembling', 'precipitating', 'king', 'continuing', 'living', 'enslaving', 'confining', 'king', 'quitting', 'king', 'king', 'keeping', 'writing', 'king', 'king', 'shining', 'bearing', 'frightening', 'letting', 'king', 'king', 'swimming', 'king', 'surpassing', 'king', 'boiling', 'king', 'reasoning', 'writing', 'king', 'sitting', 'converting', 'springing', 'lightning', 'plaything', 'king', 'interesting', 'king', 'king', 'tightening', 'bowstring', 'depriving'], 'RBR': ['farther', 'father', 'wore', 'wider', 'monster', 'enter', 'limbs', 'sooner'], 'VBZ': ['puts', 'appears', 'forgets', 'isits', 'isits', 'fulfil', 'relates', 'streets', 'animals', 'chickens', 'brains', 'veins', 'wives', 'husbands', 'shapes', 'consists', 'lies', 'lies'], 'CD': ['vow'], 'IN': ['devout', 'vizier', 'breast', 'vessel', 'alike', 'beneath', 'mankind', 'mile', 'nonsense'], 'VB': ['fear', 'head', 'feel', 'remember', 'hill', 'cave', 'gems', 'flock', 'watch'], 'JJR': ['vizier', 'vizier', 'worse', 'louder', 'larger', 'larger', 'greater', 'larger', 'richer', 'larger', 'bigger', 'fewer', 'bigger'], 'JJS': ['slightest', 'loftiest', 'greatest', 'infest', 'finest', 'darkest', 'whitest', 'forest', 'biggest', 'grandest', 'finest', 'mightiest'], 'MD': ['outright'], 'PRP$': ['heir'], 'RP': ['ornot', 'ornot'], 'FW': ['secret']}\n"
     ]
    }
   ],
   "source": [
    "penn_tagged = {}\n",
    "for sent in all_tagged:\n",
    "    for word in sent:\n",
    "        if tagdict.get(word[1]):\n",
    "            try:\n",
    "                penn_tagged[word[1]].append(word[0])\n",
    "            except:\n",
    "                penn_tagged[word[1]] = [word[0]]\n",
    "print(penn_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b571f",
   "metadata": {},
   "source": [
    "### q4 stories dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e296f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---+---+--------------------+---+---+---+--------------------+---+--------------------+-----+---+---+---+---+---+---+---+---+---+--------------------+--------------------+-------+---+--------------------+---+---+---+---+---+--------------------+---+---+\n",
      "|   title|                text| LS| TO|                  VB| ''| WP| UH|                  JJ| --|                  NN|   DT| PR|  :| WD|  (|  )|  .|  ,| ``|  $|                  RB|                  IN|     FW| RP|                  JJ| PD| MD| WR| EX| SY|                  CC| CD| PO|\n",
      "+--------+--------------------+---+---+--------------------+---+---+---+--------------------+---+--------------------+-----+---+---+---+---+---+---+---+---+---+--------------------+--------------------+-------+---+--------------------+---+---+---+---+---+--------------------+---+---+\n",
      "| Bernice|nullus enim locus...|   |   |contes, insisted,...|   |   |   |nullus, enim, mor...|   |locus, sine, geni...|     |   |   |   |   |   |   |   |   |   |mockery, lui, ful...|love, profound, a...| quelqu|   |nullus, enim, mor...|   |   |   |   |   |                    |   |   |\n",
      "|Eleonora|doubt envelop rat...|   |   |envelop, startlin...|   |   |   |rationale, mere, ...|   |doubt, mesmerism,...|ether|   |   |   |   |   |   |   |   |   |universally, mere...|profound, profoun...|vankirk|   |rationale, mere, ...|   |   |   |   |   |ether, ether, eth...|   |   |\n",
      "+--------+--------------------+---+---+--------------------+---+---+---+--------------------+---+--------------------+-----+---+---+---+---+---+---+---+---+---+--------------------+--------------------+-------+---+--------------------+---+---+---+---+---+--------------------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# step 1: change the tags dictionary to only containing first two letters\n",
    "def get_dict(text):\n",
    "    result = {}\n",
    "    sent_text = nltk.sent_tokenize(text) # this gives us a list of sentences\n",
    "    # now loop over each sentence and tokenize it separately\n",
    "    tagged = [nltk.pos_tag(nltk.word_tokenize(sent)) for sent in sent_text] \n",
    "    for sent in tagged:\n",
    "        for word in sent:\n",
    "            # making sure all the keys in result only contain the first 2 letters of the tags\n",
    "            if tagdict.get(word[1]):\n",
    "                if len(word[1]) <= 2:\n",
    "                    try:\n",
    "                        result[word[1]].append(word[0])\n",
    "                    except:\n",
    "                        result[word[1]] = [word[0]]\n",
    "                else:\n",
    "                    try:\n",
    "                        result[word[1][:2]].append(word[0])\n",
    "                    except:\n",
    "                        result[word[1][:2]] = [word[0]]\n",
    "    return result\n",
    "\n",
    "# step 2: make the dataframe with columns of ['title',text',LS', 'TO', 'VB', \"''\", 'WP', 'UH', 'JJ',  '--', 'NN', 'DT', 'PR', ':','WD', '(', ')', '.', ',', '``', '$', 'RB', 'IN', 'FW', 'RP', 'JJ', 'PDT', 'MD', 'WRB',  'EX',  'SY', 'CC', 'CD', 'PO']\n",
    "def generate_df(titles, texts):\n",
    "    all_data = []\n",
    "    # column for the dataframe\n",
    "    column = ['title','text','LS', 'TO', 'VB', \"''\", 'WP', 'UH', '--', 'NN', 'DT', 'PR', ':','WD', '(', ')', '.', ',', '``', '$', 'RB', 'IN', 'FW', 'RP', 'JJ', 'PD', 'MD', 'WR',  'EX',  'SY', 'CC', 'CD', 'PO']\n",
    "    # generate the row of data for each story\n",
    "    for (title, text) in zip(titles, texts):\n",
    "        # generating a dictionary of tags and words\n",
    "        tagged_words = get_dict(text)\n",
    "        data = [title, text]\n",
    "        for tag in column[2:]:\n",
    "            if tagged_words.get(tag):\n",
    "                data.append(', '.join(tagged_words[tag]))\n",
    "            else:\n",
    "                data.append('')\n",
    "        all_data.append(data)\n",
    "    # generate the dataframe\n",
    "    df = spark.createDataFrame(all_data, column) \n",
    "    return df\n",
    "\n",
    "# testing\n",
    "generate_df(['Bernice', 'Eleonora'], [cleaned[1],cleaned[2]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbed97",
   "metadata": {},
   "source": [
    "### q5 - proportions of POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55eec1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+-------------------+---+--------------------+---+---+-------------------+--------------------+--------------------+---+---+---+---+---+---+---+---+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+---+--------------------+---+--------------------+--------------------+---+\n",
      "|               title| LS| TO|                 VB| ''|                  WP| UH| --|                 NN|                  DT|                  PR|  :| WD|  (|  )|  .|  ,| ``|  $|                  RB|                  IN|                  FW|                  RP|                 JJ|                  PD|                  MD|WRB|                  EX| SY|                  CC|                  CD| PO|\n",
      "+--------------------+---+---+-------------------+---+--------------------+---+---+-------------------+--------------------+--------------------+---+---+---+---+---+---+---+---+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+---+--------------------+---+--------------------+--------------------+---+\n",
      "|THE_THOUSAND-AND-...|  0|  0| 0.2221105527638191|  0|                   0|  0|  0| 0.4949748743718593|                   0|0.000502512562814...|  0|  0|  0|  0|  0|  0|  0|  0| 0.05125628140703518|0.004522613065326633|0.000502512562814...|0.001005025125628...| 0.2241206030150754|                   0|0.000502512562814...|  0|                   0|  0|                   0|0.000502512562814...|  0|\n",
      "|THE_ISLAND_OF_THE...|  0|  0|0.21846553966189858|  0|                   0|  0|  0|  0.459037711313394|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0|  0.0611183355006502|0.009102730819245773|0.001300390117035...|                   0|0.25097529258777634|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "| MESMERIC_REVELATION|  0|  0|0.17727272727272728|  0|                   0|  0|  0| 0.5159090909090909|0.000757575757575...|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.05303030303030303|0.003030303030303...|0.000757575757575...|                   0|0.24621212121212122|                   0|                   0|  0|                   0|  0|0.003030303030303...|                   0|  0|\n",
      "|A_DESCENT_INTO_TH...|  0|  0|0.21524852569502947|  0|                   0|  0|  0|  0.491575400168492|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06402695871946082|0.007160909856781803|0.000842459983150...|                   0|0.22114574557708508|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|VON_KEMPELEN_AND_...|  0|  0|0.21891058581706063|  0|                   0|  0|  0|0.47173689619732784|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06372045220966084|0.003083247687564234|0.002055498458376...|0.001027749229188...|0.23638232271325796|0.001027749229188...|                   0|  0|                   0|  0|                   0|0.002055498458376...|  0|\n",
      "|THE_DOMAIN_OF_ARN...|  0|  0| 0.1984093763080787|  0|                   0|  0|  0| 0.4947676852239431|                   0|0.000418585182084...|  0|  0|  0|  0|  0|  0|  0|  0| 0.05064880703223106|0.004604437002930...|0.001674340728338...|0.000837170364169...| 0.2486395981582252|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|THE_FALL_OF_THE_H...|  0|  0| 0.2192266761262859|  0|0.000354735721887194|  0|  0|0.46789641716920893|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06349769421780774|0.004611564384533...|0.000354735721887194|0.000354735721887194|0.24263923377084073|                   0|                   0|  0|                   0|  0|                   0|0.000709471443774388|  0|\n",
      "|THE_PIT_AND_THE_P...|  0|  0|0.24462596732588135|  0|                   0|  0|  0|0.47764402407566636|0.000429922613929...|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06018916595012898|0.005588993981083405|                   0|                   0| 0.2115219260533104|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|       THE_BLACK_CAT|  0|  0|0.22049469964664312|  0|                   0|  0|  0|0.48480565371024736|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0|  0.0558303886925795|0.004240282685512367|                   0|                   0|0.23392226148409895|                   0|                   0|  0|0.000706713780918...|  0|                   0|                   0|  0|\n",
      "|     SILENCE-A_FABLE|  0|  0| 0.2303370786516854|  0|                   0|  0|  0| 0.4794007490636704|0.001872659176029...|0.001872659176029...|  0|  0|  0|  0|  0|  0|  0|  0| 0.06741573033707865|0.003745318352059925|                   0|                   0| 0.2153558052434457|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|THE_IMP_OF_THE_PE...|  0|  0|0.20649651972157773|  0|                   0|  0|  0| 0.4965197215777262|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0|0.054524361948955914|0.006960556844547...|                   0|                   0| 0.2354988399071926|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|THE_FACTS_IN_THE_...|  0|  0|0.21862348178137653|  0|                   0|  0|  0|0.46558704453441296|0.000809716599190...|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06882591093117409|0.002429149797570...|                   0|                   0|  0.242914979757085|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|THE_PURLOINED_LETTER|  0|  0|  0.220703933747412|  0|                   0|  0|  0| 0.5072463768115942|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0|  0.0443064182194617|0.005383022774327122|0.001242236024844...|                   0|  0.220703933747412|                   0|                   0|  0|                   0|  0|                   0|0.000414078674948...|  0|\n",
      "|THE_PREMATURE_BURIAL|  0|  0|0.22851834649326522|  0|                   0|  0|  0|0.46261031119368323|                   0|0.000464468183929...|  0|  0|  0|  0|  0|  0|  0|  0| 0.06316767301439852|0.002786809103576405|0.000928936367858...|                   0|0.24059451927542963|                   0|                   0|  0|                   0|  0|                   0|0.000928936367858...|  0|\n",
      "|            ELEONORA|  0|  0|0.23605150214592274|  0|                   0|  0|  0|0.47532188841201717|0.001072961373390558|                   0|  0|  0|  0|  0|  0|  0|  0|  0|0.059012875536480686|0.001072961373390558|0.002145922746781116|                   0|0.22424892703862662|                   0|                   0|  0|                   0|  0|0.001072961373390558|                   0|  0|\n",
      "|THE_MASQUE_OF_THE...|  0|  0| 0.2210184182015168|  0|                   0|  0|  0| 0.5005417118093174|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.05308775731310943|0.003250270855904...|0.001083423618634...|                   0| 0.2210184182015168|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|     THE_ASSIGNATION|  0|  0| 0.2259154929577465|  0|                   0|  0|  0|  0.483943661971831|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0|0.049014084507042255|0.003943661971830986|0.002253521126760...|                   0|0.23492957746478874|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|            BERENICE|  0|  0|0.21904761904761905|  0|                   0|  0|  0| 0.4714285714285714|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06190476190476191|0.003174603174603...|0.002380952380952381|                   0|0.24206349206349206|                   0|                   0|  0|                   0|  0|                   0|                   0|  0|\n",
      "|THE_CASK_OF_AMONT...|  0|  0|0.22163699568102813|  0|5.267038870746866...|  0|  0|0.47313810175919097|0.000158011166122...|0.000158011166122...|  0|  0|  0|  0|  0|  0|  0|  0| 0.05883282418624249|0.004793005372379648|0.001000737385441...|0.000263351943537...|0.23954492784156747|                   0|5.267038870746866...|  0|                   0|  0|0.000158011166122...|0.000105340777414...|  0|\n",
      "|     LANDORS_COTTAGE|  0|  0|0.19380252100840337|  0|0.000525210084033...|  0|  0| 0.4574579831932773|                   0|                   0|  0|  0|  0|  0|  0|  0|  0|  0| 0.06722689075630252|0.004726890756302521|0.000525210084033...|                   0|0.27521008403361347|                   0|                   0|  0|                   0|  0|0.000525210084033...|                   0|  0|\n",
      "+--------------------+---+---+-------------------+---+--------------------+---+---+-------------------+--------------------+--------------------+---+---+---+---+---+---+---+---+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+---+--------------------+---+--------------------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_POS_freq(titles, texts):\n",
    "    all_data = []\n",
    "    # column for the dataframe\n",
    "    column = ['title','LS', 'TO', 'VB', \"''\", 'WP', 'UH', '--', 'NN', 'DT', 'PR', ':','WD', '(', ')', '.', ',', '``', '$', 'RB', 'IN', 'FW', 'RP', 'JJ', 'PD', 'MD', 'WRB',  'EX',  'SY', 'CC', 'CD', 'PO']\n",
    "    # generate the row of data for each story\n",
    "    for (title, text) in zip(titles, texts):\n",
    "        # generating a dictionary of tags and words\n",
    "        tagged_words = get_dict(text)\n",
    "        data = [title]\n",
    "        # get the total number of words in text\n",
    "        total_num_words = len(text.split(' '))\n",
    "        for tag in column[1:]:\n",
    "            if tagged_words.get(tag):\n",
    "                data.append(str(len(tagged_words[tag])/total_num_words))\n",
    "            else:\n",
    "                data.append(0)\n",
    "        all_data.append(data)\n",
    "    # generate the dataframe\n",
    "    df = spark.createDataFrame(all_data, column) \n",
    "    df.repartition(1).write.format('com.databricks.spark.csv').save(\"POS.csv\",header = 'true')\n",
    "    return df\n",
    "\n",
    "# testing\n",
    "get_POS_freq(['THE_THOUSAND-AND-SECOND_TALE_OF_SCHEHERAZADE', 'THE_ISLAND_OF_THE_FAY', 'MESMERIC_REVELATION', 'A_DESCENT_INTO_THE_MAELSTROM', 'VON_KEMPELEN_AND_HIS_DISCOVERY', 'THE_DOMAIN_OF_ARNHEIM', 'THE_FALL_OF_THE_HOUSE_OF_USHER', 'THE_PIT_AND_THE_PENDULUM', 'THE_BLACK_CAT', 'SILENCE-A_FABLE', 'THE_IMP_OF_THE_PERVERSE', 'THE_FACTS_IN_THE_CASE_OF_M._VALDEMAR', 'THE_PURLOINED_LETTER', 'THE_PREMATURE_BURIAL', 'ELEONORA', 'THE_MASQUE_OF_THE_RED_DEATH', 'THE_ASSIGNATION', 'BERENICE', 'THE_CASK_OF_AMONTILLADO', 'LANDORS_COTTAGE', 'WILLIAM_WILSON'], cleaned).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
